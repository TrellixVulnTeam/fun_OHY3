11/01/2020 15:06:58 - INFO - __main__ -  817 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 15:07:12 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 15:07:12 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 15:07:12 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:07:12 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 15:07:12 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:07:12 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 15:07:12 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:07:12 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 15:07:12 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:07:12 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 15:07:12 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:07:12 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 15:07:22 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 15:07:22 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmprlrw9pzl
11/01/2020 15:07:26 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 15:07:29 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 15:07:29 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 15:07:29 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 15:07:29 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:07:29 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 15:07:29 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 15:07:29 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:07:29 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:07:29 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 15:07:29 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 15:07:29 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:07:29 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:07:29 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 15:07:29 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 15:07:29 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:07:29 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:07:29 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 15:07:29 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 15:07:29 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:07:29 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:07:29 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 15:07:29 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 15:07:29 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:07:29 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:07:29 - INFO - __main__ -  923 -   ***** Running training *****
11/01/2020 15:07:29 - INFO - __main__ -  924 -     Num examples = 18
11/01/2020 15:07:29 - INFO - __main__ -  925 -     Batch size = 16
11/01/2020 15:07:29 - INFO - __main__ -  926 -     Num steps = 1
11/01/2020 15:08:11 - INFO - __main__ -  817 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 15:08:26 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 15:08:26 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 15:08:26 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:08:26 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 15:08:26 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:08:26 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 15:08:26 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:08:26 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 15:08:26 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:08:26 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 15:08:26 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:08:26 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 15:13:22 - INFO - __main__ -  817 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 15:13:23 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 15:13:23 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 15:13:23 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:13:23 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 15:13:23 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:13:23 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 15:13:23 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:13:23 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 15:13:23 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:13:23 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 15:13:23 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:13:23 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 15:13:24 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 15:13:24 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpm_kdi88a
11/01/2020 15:13:29 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 15:13:31 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 15:13:31 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 15:13:31 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 15:13:31 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:13:31 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 15:13:31 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 15:13:31 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:13:31 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:13:31 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 15:13:31 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 15:13:31 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:13:31 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:13:31 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 15:13:31 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 15:13:31 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:13:31 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:13:31 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 15:13:31 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 15:13:31 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:13:31 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:13:31 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 15:13:31 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 15:13:31 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:31 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:13:31 - INFO - __main__ -  923 -   ***** Running training *****
11/01/2020 15:13:31 - INFO - __main__ -  924 -     Num examples = 18
11/01/2020 15:13:31 - INFO - __main__ -  925 -     Batch size = 16
11/01/2020 15:13:31 - INFO - __main__ -  926 -     Num steps = 1
11/01/2020 15:13:44 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/01/2020 15:13:44 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 15:13:46 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/01/2020 15:13:46 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:13:46 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/01/2020 15:13:46 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:13:46 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/01/2020 15:13:46 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:13:46 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/01/2020 15:13:46 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:13:46 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/01/2020 15:13:46 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:13:46 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/01/2020 15:13:46 - INFO - __main__ -  483 -   Writing example 0 of 12
11/01/2020 15:13:46 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:13:46 - INFO - __main__ -  550 -   guid: dev-1
11/01/2020 15:13:46 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/01/2020 15:13:46 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:13:46 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:13:46 - INFO - __main__ -  550 -   guid: dev-2
11/01/2020 15:13:46 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/01/2020 15:13:46 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:13:46 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:13:46 - INFO - __main__ -  550 -   guid: dev-3
11/01/2020 15:13:46 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/01/2020 15:13:46 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:13:46 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:13:46 - INFO - __main__ -  550 -   guid: dev-4
11/01/2020 15:13:46 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/01/2020 15:13:46 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:13:46 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:13:46 - INFO - __main__ -  550 -   guid: dev-5
11/01/2020 15:13:46 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/01/2020 15:13:46 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:13:46 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:13:46 - INFO - __main__ -  1051 -   ***** Running evaluation *****
11/01/2020 15:13:46 - INFO - __main__ -  1052 -     Num examples = 12
11/01/2020 15:13:46 - INFO - __main__ -  1053 -     Batch size = 8
11/01/2020 15:13:50 - INFO - __main__ -  1125 -   ***** Eval results *****
11/01/2020 15:13:50 - INFO - __main__ -  1127 -     acc = {'acc': 0.5, 'm_f1': 0.48571428571428577, 'w_f1': 0.45714285714285713}
11/01/2020 15:13:50 - INFO - __main__ -  1127 -     eval_loss = 0.851728081703186
11/01/2020 15:13:50 - INFO - __main__ -  1127 -     global_step = 2
11/01/2020 15:13:50 - INFO - __main__ -  1127 -     loss = 0.5978153049945831
11/01/2020 15:42:12 - INFO - __main__ -  817 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 15:42:33 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 15:42:33 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 15:42:33 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:42:33 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 15:42:33 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:42:33 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 15:42:33 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:42:33 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 15:42:33 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:42:33 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 15:42:33 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:42:33 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 15:42:54 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 15:42:54 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpvaeov81g
11/01/2020 15:42:58 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 15:43:01 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 15:43:01 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 15:43:01 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 15:43:01 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:43:01 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 15:43:01 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 15:43:01 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:43:01 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:43:01 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 15:43:01 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 15:43:01 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:43:01 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:43:01 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 15:43:01 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 15:43:01 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:43:01 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:43:01 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 15:43:01 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 15:43:01 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:43:01 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:43:01 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 15:43:01 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 15:43:01 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:43:01 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:43:01 - INFO - __main__ -  923 -   ***** Running training *****
11/01/2020 15:43:01 - INFO - __main__ -  924 -     Num examples = 18
11/01/2020 15:43:01 - INFO - __main__ -  925 -     Batch size = 16
11/01/2020 15:43:01 - INFO - __main__ -  926 -     Num steps = 1
11/01/2020 15:46:24 - INFO - __main__ -  817 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 15:47:09 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 15:47:09 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 15:47:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:47:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 15:47:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:47:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 15:47:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:47:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 15:47:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:47:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 15:47:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:47:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 15:47:10 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 15:47:10 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpjr0ar_g6
11/01/2020 15:47:14 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 15:47:17 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 15:47:17 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 15:47:17 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 15:47:17 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:47:17 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 15:47:17 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 15:47:17 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:47:17 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:47:17 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 15:47:17 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 15:47:17 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:47:17 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:47:17 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 15:47:17 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 15:47:17 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:47:17 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:47:17 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 15:47:17 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 15:47:17 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:47:17 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:47:17 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 15:47:17 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 15:47:17 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:17 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:47:17 - INFO - __main__ -  923 -   ***** Running training *****
11/01/2020 15:47:17 - INFO - __main__ -  924 -     Num examples = 18
11/01/2020 15:47:17 - INFO - __main__ -  925 -     Batch size = 16
11/01/2020 15:47:17 - INFO - __main__ -  926 -     Num steps = 1
11/01/2020 15:47:29 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/01/2020 15:47:29 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 15:47:32 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/01/2020 15:47:32 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:47:32 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/01/2020 15:47:32 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:47:32 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/01/2020 15:47:32 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:47:32 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/01/2020 15:47:32 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:47:32 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/01/2020 15:47:32 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:47:32 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/01/2020 15:47:32 - INFO - __main__ -  483 -   Writing example 0 of 12
11/01/2020 15:47:32 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:47:32 - INFO - __main__ -  550 -   guid: dev-1
11/01/2020 15:47:32 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/01/2020 15:47:32 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:47:32 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:47:32 - INFO - __main__ -  550 -   guid: dev-2
11/01/2020 15:47:32 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/01/2020 15:47:32 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:47:32 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:47:32 - INFO - __main__ -  550 -   guid: dev-3
11/01/2020 15:47:32 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/01/2020 15:47:32 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:47:32 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:47:32 - INFO - __main__ -  550 -   guid: dev-4
11/01/2020 15:47:32 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/01/2020 15:47:32 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:47:32 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:47:32 - INFO - __main__ -  550 -   guid: dev-5
11/01/2020 15:47:32 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/01/2020 15:47:32 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:47:32 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:47:32 - INFO - __main__ -  1058 -   ***** Running evaluation *****
11/01/2020 15:47:32 - INFO - __main__ -  1059 -     Num examples = 12
11/01/2020 15:47:32 - INFO - __main__ -  1060 -     Batch size = 8
11/01/2020 15:47:34 - INFO - __main__ -  1136 -   ***** Eval results *****
11/01/2020 15:47:34 - INFO - __main__ -  1138 -     acc = {'acc': 0.5, 'm_f1': 0.48571428571428577, 'w_f1': 0.45714285714285713}
11/01/2020 15:47:34 - INFO - __main__ -  1138 -     eval_loss = 0.851728081703186
11/01/2020 15:47:34 - INFO - __main__ -  1138 -     global_step = 2
11/01/2020 15:47:34 - INFO - __main__ -  1138 -     loss = 0.5978153049945831
11/01/2020 15:52:06 - INFO - __main__ -  817 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 15:52:07 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 15:52:07 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 15:52:07 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:52:07 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 15:52:07 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:52:07 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 15:52:07 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:52:07 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 15:52:07 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:52:07 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 15:52:07 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:52:07 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 15:52:08 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 15:52:08 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmppq78fy20
11/01/2020 15:52:13 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 15:52:15 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 15:52:15 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 15:52:15 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 15:52:15 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:52:15 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 15:52:15 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 15:52:15 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:52:15 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:52:15 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 15:52:15 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 15:52:15 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:52:15 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:52:15 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 15:52:15 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 15:52:15 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:52:15 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:52:15 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 15:52:15 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 15:52:15 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:52:15 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:52:15 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 15:52:15 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 15:52:15 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:15 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:52:15 - INFO - __main__ -  923 -   ***** Running training *****
11/01/2020 15:52:15 - INFO - __main__ -  924 -     Num examples = 18
11/01/2020 15:52:15 - INFO - __main__ -  925 -     Batch size = 16
11/01/2020 15:52:15 - INFO - __main__ -  926 -     Num steps = 2
11/01/2020 15:52:41 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/01/2020 15:52:44 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/01/2020 15:52:44 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 15:52:48 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/01/2020 15:52:48 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:52:48 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/01/2020 15:52:48 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:52:48 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/01/2020 15:52:48 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:52:48 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/01/2020 15:52:48 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:52:48 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/01/2020 15:52:48 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 15:52:48 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/01/2020 15:52:48 - INFO - __main__ -  483 -   Writing example 0 of 12
11/01/2020 15:52:48 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:52:48 - INFO - __main__ -  550 -   guid: dev-1
11/01/2020 15:52:48 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/01/2020 15:52:48 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:52:48 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:52:48 - INFO - __main__ -  550 -   guid: dev-2
11/01/2020 15:52:48 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/01/2020 15:52:48 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 15:52:48 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:52:48 - INFO - __main__ -  550 -   guid: dev-3
11/01/2020 15:52:48 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/01/2020 15:52:48 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:52:48 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:52:48 - INFO - __main__ -  550 -   guid: dev-4
11/01/2020 15:52:48 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/01/2020 15:52:48 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:52:48 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 15:52:48 - INFO - __main__ -  550 -   guid: dev-5
11/01/2020 15:52:48 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/01/2020 15:52:48 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 15:52:48 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 15:52:48 - INFO - __main__ -  1058 -   ***** Running evaluation *****
11/01/2020 15:52:48 - INFO - __main__ -  1059 -     Num examples = 12
11/01/2020 15:52:48 - INFO - __main__ -  1060 -     Batch size = 8
11/01/2020 15:52:50 - INFO - __main__ -  1135 -   ***** Eval results *****
11/01/2020 15:52:50 - INFO - __main__ -  1137 -     acc = {'acc': 0.5833333333333334, 'm_f1': 0.5804195804195804, 'w_f1': 0.5687645687645687}
11/01/2020 15:52:50 - INFO - __main__ -  1137 -     eval_loss = 0.7921589612960815
11/01/2020 15:52:50 - INFO - __main__ -  1137 -     global_step = 4
11/01/2020 15:52:50 - INFO - __main__ -  1137 -     loss = 0.2999415844678879
11/01/2020 16:06:53 - INFO - __main__ -  817 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 16:06:54 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 16:06:54 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 16:06:54 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:06:54 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 16:06:54 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:06:54 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 16:06:54 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:06:54 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 16:06:54 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:06:54 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 16:06:54 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:06:54 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 16:12:50 - INFO - __main__ -  816 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 16:12:51 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 16:12:51 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 16:12:51 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:12:51 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 16:12:51 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:12:51 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 16:12:51 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:12:51 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 16:12:51 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:12:51 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 16:12:51 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:12:51 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 16:12:52 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 16:12:52 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpptbs_rzq
11/01/2020 16:12:58 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 16:13:00 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 16:13:00 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 16:13:00 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 16:13:00 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:13:00 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 16:13:00 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 16:13:00 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:13:00 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:13:00 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 16:13:00 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 16:13:00 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:13:00 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:13:00 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 16:13:00 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 16:13:00 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:13:00 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:13:00 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 16:13:00 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 16:13:00 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:13:00 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:13:00 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 16:13:00 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 16:13:00 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:13:00 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:13:00 - INFO - __main__ -  922 -   ***** Running training *****
11/01/2020 16:13:00 - INFO - __main__ -  923 -     Num examples = 18
11/01/2020 16:13:00 - INFO - __main__ -  924 -     Batch size = 16
11/01/2020 16:13:00 - INFO - __main__ -  925 -     Num steps = 2
11/01/2020 16:19:46 - INFO - __main__ -  816 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 16:19:47 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 16:19:47 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 16:19:47 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:19:47 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 16:19:47 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:19:47 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 16:19:47 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:19:47 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 16:19:47 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:19:47 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 16:19:47 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:19:47 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 16:19:50 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 16:19:50 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpv33vqr0d
11/01/2020 16:19:53 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 16:19:56 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 16:19:56 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 16:19:56 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 16:19:56 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:19:56 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 16:19:56 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 16:19:56 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:19:56 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:19:56 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 16:19:56 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 16:19:56 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:19:56 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:19:56 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 16:19:56 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 16:19:56 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:19:56 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:19:56 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 16:19:56 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 16:19:56 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:19:56 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:19:56 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 16:19:56 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 16:19:56 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:19:56 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:19:56 - INFO - __main__ -  922 -   ***** Running training *****
11/01/2020 16:19:56 - INFO - __main__ -  923 -     Num examples = 18
11/01/2020 16:19:56 - INFO - __main__ -  924 -     Batch size = 16
11/01/2020 16:19:56 - INFO - __main__ -  925 -     Num steps = 2
11/01/2020 16:21:56 - INFO - __main__ -  816 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 16:21:57 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 16:21:57 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 16:21:57 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:21:57 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 16:21:57 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:21:57 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 16:21:57 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:21:57 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 16:21:57 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:21:57 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 16:21:57 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:21:57 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 16:21:58 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 16:21:58 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpdtsst7oq
11/01/2020 16:22:02 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 16:22:05 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 16:22:05 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 16:22:05 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 16:22:05 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:22:05 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 16:22:05 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 16:22:05 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:22:05 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:22:05 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 16:22:05 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 16:22:05 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:22:05 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:22:05 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 16:22:05 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 16:22:05 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:22:05 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:22:05 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 16:22:05 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 16:22:05 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:22:05 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:22:05 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 16:22:05 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 16:22:05 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:22:05 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:22:05 - INFO - __main__ -  922 -   ***** Running training *****
11/01/2020 16:22:05 - INFO - __main__ -  923 -     Num examples = 18
11/01/2020 16:22:05 - INFO - __main__ -  924 -     Batch size = 16
11/01/2020 16:22:05 - INFO - __main__ -  925 -     Num steps = 2
11/01/2020 16:26:08 - INFO - __main__ -  816 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 16:26:09 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 16:26:09 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 16:26:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:26:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 16:26:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:26:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 16:26:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:26:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 16:26:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:26:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 16:26:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:26:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 16:26:11 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 16:26:12 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmptfz7jc20
11/01/2020 16:26:15 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 16:26:18 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 16:26:18 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 16:26:18 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 16:26:18 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:26:18 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 16:26:18 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 16:26:18 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:26:18 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:26:18 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 16:26:18 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 16:26:18 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:26:18 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:26:18 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 16:26:18 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 16:26:18 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:26:18 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:26:18 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 16:26:18 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 16:26:18 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:26:18 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:26:18 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 16:26:18 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 16:26:18 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:26:18 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:26:18 - INFO - __main__ -  922 -   ***** Running training *****
11/01/2020 16:26:18 - INFO - __main__ -  923 -     Num examples = 18
11/01/2020 16:26:18 - INFO - __main__ -  924 -     Batch size = 16
11/01/2020 16:26:18 - INFO - __main__ -  925 -     Num steps = 2
11/01/2020 16:43:02 - INFO - __main__ -  816 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 16:43:03 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 16:43:03 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 16:43:03 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:43:03 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 16:43:03 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:43:03 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 16:43:03 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:43:03 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 16:43:03 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:43:03 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 16:43:03 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:43:03 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 16:43:05 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 16:43:05 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmprzznsy8a
11/01/2020 16:43:09 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 16:43:12 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 16:43:12 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 16:43:12 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 16:43:12 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:43:12 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 16:43:12 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 16:43:12 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:43:12 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:43:12 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 16:43:12 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 16:43:12 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:43:12 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:43:12 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 16:43:12 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 16:43:12 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:43:12 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:43:12 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 16:43:12 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 16:43:12 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:43:12 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:43:12 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 16:43:12 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 16:43:12 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:12 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:43:12 - INFO - __main__ -  922 -   ***** Running training *****
11/01/2020 16:43:12 - INFO - __main__ -  923 -     Num examples = 18
11/01/2020 16:43:12 - INFO - __main__ -  924 -     Batch size = 16
11/01/2020 16:43:12 - INFO - __main__ -  925 -     Num steps = 2
11/01/2020 16:43:33 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/01/2020 16:43:36 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/01/2020 16:43:36 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 16:43:39 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/01/2020 16:43:39 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:43:39 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/01/2020 16:43:39 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:43:39 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/01/2020 16:43:39 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:43:39 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/01/2020 16:43:39 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:43:39 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/01/2020 16:43:39 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:43:39 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/01/2020 16:43:39 - INFO - __main__ -  483 -   Writing example 0 of 12
11/01/2020 16:43:39 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:43:39 - INFO - __main__ -  550 -   guid: dev-1
11/01/2020 16:43:39 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/01/2020 16:43:39 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:43:39 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:43:39 - INFO - __main__ -  550 -   guid: dev-2
11/01/2020 16:43:39 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/01/2020 16:43:39 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:43:39 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:43:39 - INFO - __main__ -  550 -   guid: dev-3
11/01/2020 16:43:39 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/01/2020 16:43:39 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:43:39 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:43:39 - INFO - __main__ -  550 -   guid: dev-4
11/01/2020 16:43:39 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/01/2020 16:43:39 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:43:39 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:43:39 - INFO - __main__ -  550 -   guid: dev-5
11/01/2020 16:43:39 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/01/2020 16:43:39 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:43:39 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:43:39 - INFO - __main__ -  1059 -   ***** Running evaluation *****
11/01/2020 16:43:39 - INFO - __main__ -  1060 -     Num examples = 12
11/01/2020 16:43:39 - INFO - __main__ -  1061 -     Batch size = 8
11/01/2020 16:43:41 - INFO - __main__ -  1136 -   ***** Eval results *****
11/01/2020 16:43:41 - INFO - __main__ -  1138 -     acc = {'acc': 0.5833333333333334, 'm_f1': 0.5804195804195804, 'w_f1': 0.5687645687645687}
11/01/2020 16:43:41 - INFO - __main__ -  1138 -     eval_loss = 0.7921589612960815
11/01/2020 16:43:41 - INFO - __main__ -  1138 -     global_step = 4
11/01/2020 16:43:41 - INFO - __main__ -  1138 -     loss = 0.2999415844678879
11/01/2020 16:46:08 - INFO - __main__ -  816 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 16:46:20 - INFO - __main__ -  816 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 16:46:59 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 16:46:59 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 16:46:59 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:46:59 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 16:46:59 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:46:59 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 16:46:59 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:46:59 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 16:46:59 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:46:59 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 16:46:59 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:46:59 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 16:47:02 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 16:47:02 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpkj4_ggjw
11/01/2020 16:47:05 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 16:47:08 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 16:47:08 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 16:47:08 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 16:47:08 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:47:08 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 16:47:08 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 16:47:08 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:47:08 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:47:08 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 16:47:08 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 16:47:08 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:47:08 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:47:08 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 16:47:08 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 16:47:08 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:47:08 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:47:08 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 16:47:08 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 16:47:08 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:47:08 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:47:08 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 16:47:08 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 16:47:08 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:08 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:47:08 - INFO - __main__ -  922 -   ***** Running training *****
11/01/2020 16:47:08 - INFO - __main__ -  923 -     Num examples = 18
11/01/2020 16:47:08 - INFO - __main__ -  924 -     Batch size = 16
11/01/2020 16:47:08 - INFO - __main__ -  925 -     Num steps = 2
11/01/2020 16:47:30 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/01/2020 16:47:32 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/01/2020 16:47:32 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 16:47:35 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/01/2020 16:47:35 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:47:35 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/01/2020 16:47:35 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:47:35 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/01/2020 16:47:35 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:47:35 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/01/2020 16:47:35 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:47:35 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/01/2020 16:47:35 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 16:47:35 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/01/2020 16:47:35 - INFO - __main__ -  483 -   Writing example 0 of 12
11/01/2020 16:47:35 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:47:35 - INFO - __main__ -  550 -   guid: dev-1
11/01/2020 16:47:35 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/01/2020 16:47:35 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:47:35 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:47:35 - INFO - __main__ -  550 -   guid: dev-2
11/01/2020 16:47:35 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/01/2020 16:47:35 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 16:47:35 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:47:35 - INFO - __main__ -  550 -   guid: dev-3
11/01/2020 16:47:35 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/01/2020 16:47:35 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:47:35 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:47:35 - INFO - __main__ -  550 -   guid: dev-4
11/01/2020 16:47:35 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/01/2020 16:47:35 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:47:35 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 16:47:35 - INFO - __main__ -  550 -   guid: dev-5
11/01/2020 16:47:35 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/01/2020 16:47:35 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 16:47:35 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 16:47:35 - INFO - __main__ -  1059 -   ***** Running evaluation *****
11/01/2020 16:47:35 - INFO - __main__ -  1060 -     Num examples = 12
11/01/2020 16:47:35 - INFO - __main__ -  1061 -     Batch size = 8
11/01/2020 16:47:37 - INFO - __main__ -  1136 -   ***** Eval results *****
11/01/2020 16:47:37 - INFO - __main__ -  1138 -     acc = {'acc': 0.5833333333333334, 'm_f1': 0.5804195804195804, 'w_f1': 0.5687645687645687}
11/01/2020 16:47:37 - INFO - __main__ -  1138 -     eval_loss = 0.7921589612960815
11/01/2020 16:47:37 - INFO - __main__ -  1138 -     global_step = 4
11/01/2020 16:47:37 - INFO - __main__ -  1138 -     loss = 0.2999415844678879
11/01/2020 21:18:17 - INFO - __main__ -  844 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 21:18:18 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 21:18:18 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 21:18:18 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:18:18 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 21:18:18 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:18:18 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 21:18:18 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:18:18 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 21:18:18 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:18:18 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 21:18:18 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:18:18 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 21:18:20 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 21:18:20 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmp5msm9r6h
11/01/2020 21:18:24 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:18:27 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 21:18:27 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 21:18:27 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 21:18:27 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:18:27 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 21:18:27 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 21:18:27 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:18:27 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:18:27 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 21:18:27 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 21:18:27 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:18:27 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:18:27 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 21:18:27 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 21:18:27 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:18:27 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:18:27 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 21:18:27 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 21:18:27 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:18:27 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:18:27 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 21:18:27 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 21:18:27 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:18:27 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:18:27 - INFO - __main__ -  950 -   ***** Running training *****
11/01/2020 21:18:27 - INFO - __main__ -  951 -     Num examples = 18
11/01/2020 21:18:27 - INFO - __main__ -  952 -     Batch size = 16
11/01/2020 21:18:27 - INFO - __main__ -  953 -     Num steps = 2
11/01/2020 21:19:02 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/01/2020 21:19:07 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/01/2020 21:19:08 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:19:11 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/01/2020 21:19:12 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:19:12 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/01/2020 21:19:12 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:19:12 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/01/2020 21:19:12 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:19:12 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/01/2020 21:19:12 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:19:12 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/01/2020 21:19:12 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:19:12 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/01/2020 21:19:12 - INFO - __main__ -  483 -   Writing example 0 of 12
11/01/2020 21:19:12 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:19:12 - INFO - __main__ -  550 -   guid: dev-1
11/01/2020 21:19:12 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/01/2020 21:19:12 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:19:12 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:19:12 - INFO - __main__ -  550 -   guid: dev-2
11/01/2020 21:19:12 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/01/2020 21:19:12 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:19:12 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:19:12 - INFO - __main__ -  550 -   guid: dev-3
11/01/2020 21:19:12 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/01/2020 21:19:12 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:19:12 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:19:12 - INFO - __main__ -  550 -   guid: dev-4
11/01/2020 21:19:12 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/01/2020 21:19:12 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:19:12 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:19:12 - INFO - __main__ -  550 -   guid: dev-5
11/01/2020 21:19:12 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/01/2020 21:19:12 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:19:12 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:19:12 - INFO - __main__ -  1087 -   ***** Running evaluation *****
11/01/2020 21:19:12 - INFO - __main__ -  1088 -     Num examples = 12
11/01/2020 21:19:12 - INFO - __main__ -  1089 -     Batch size = 8
11/01/2020 21:23:29 - INFO - __main__ -  844 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 21:23:50 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 21:23:50 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 21:23:50 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:23:50 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 21:23:50 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:23:50 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 21:23:50 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:23:50 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 21:23:50 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:23:50 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 21:23:50 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:23:50 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 21:24:11 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 21:24:11 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpn_3dtxwb
11/01/2020 21:24:16 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:24:19 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 21:24:19 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 21:24:19 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 21:24:19 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:24:19 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 21:24:19 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 21:24:19 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:24:19 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:24:19 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 21:24:19 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 21:24:19 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:24:19 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:24:19 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 21:24:19 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 21:24:19 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:24:19 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:24:19 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 21:24:19 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 21:24:19 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:24:19 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:24:19 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 21:24:19 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 21:24:19 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:19 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:24:19 - INFO - __main__ -  950 -   ***** Running training *****
11/01/2020 21:24:19 - INFO - __main__ -  951 -     Num examples = 18
11/01/2020 21:24:19 - INFO - __main__ -  952 -     Batch size = 16
11/01/2020 21:24:19 - INFO - __main__ -  953 -     Num steps = 2
11/01/2020 21:24:40 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/01/2020 21:24:43 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/01/2020 21:24:43 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:24:45 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/01/2020 21:24:45 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:24:45 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/01/2020 21:24:45 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:24:45 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/01/2020 21:24:45 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:24:45 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/01/2020 21:24:45 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:24:45 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/01/2020 21:24:45 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:24:45 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/01/2020 21:24:45 - INFO - __main__ -  483 -   Writing example 0 of 12
11/01/2020 21:24:45 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:24:45 - INFO - __main__ -  550 -   guid: dev-1
11/01/2020 21:24:45 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/01/2020 21:24:45 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:24:45 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:24:45 - INFO - __main__ -  550 -   guid: dev-2
11/01/2020 21:24:45 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/01/2020 21:24:45 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:24:45 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:24:45 - INFO - __main__ -  550 -   guid: dev-3
11/01/2020 21:24:45 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/01/2020 21:24:45 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:24:45 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:24:45 - INFO - __main__ -  550 -   guid: dev-4
11/01/2020 21:24:45 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/01/2020 21:24:45 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:24:45 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:24:45 - INFO - __main__ -  550 -   guid: dev-5
11/01/2020 21:24:45 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/01/2020 21:24:45 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:24:45 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:24:45 - INFO - __main__ -  1087 -   ***** Running evaluation *****
11/01/2020 21:24:45 - INFO - __main__ -  1088 -     Num examples = 12
11/01/2020 21:24:45 - INFO - __main__ -  1089 -     Batch size = 8
11/01/2020 21:25:37 - INFO - __main__ -  1167 -   ***** Eval results *****
11/01/2020 21:25:37 - INFO - __main__ -  1169 -     acc = {'acc': 0.5833333333333334, 'm_f1': 0.5804195804195804, 'w_f1': 0.5687645687645687}
11/01/2020 21:25:37 - INFO - __main__ -  1169 -     eval_loss = 0.7921589612960815
11/01/2020 21:25:37 - INFO - __main__ -  1169 -     global_step = 4
11/01/2020 21:25:37 - INFO - __main__ -  1169 -     loss = 0.2999415844678879
11/01/2020 21:34:05 - INFO - __main__ -  844 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 21:34:16 - INFO - __main__ -  844 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 21:34:33 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 21:34:33 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 21:34:33 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:34:33 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 21:34:33 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:34:33 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 21:34:33 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:34:33 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 21:34:33 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:34:33 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 21:34:33 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:34:33 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 21:34:34 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 21:34:34 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmps8bwuvab
11/01/2020 21:34:38 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:34:40 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 21:34:40 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 21:34:40 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 21:34:40 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:34:40 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 21:34:40 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 21:34:40 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:34:40 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:34:40 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 21:34:40 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 21:34:40 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:34:40 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:34:40 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 21:34:40 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 21:34:40 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:34:40 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:34:40 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 21:34:40 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 21:34:40 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:34:40 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:34:40 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 21:34:40 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 21:34:40 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:34:40 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:34:40 - INFO - __main__ -  950 -   ***** Running training *****
11/01/2020 21:34:40 - INFO - __main__ -  951 -     Num examples = 18
11/01/2020 21:34:40 - INFO - __main__ -  952 -     Batch size = 16
11/01/2020 21:34:40 - INFO - __main__ -  953 -     Num steps = 2
11/01/2020 21:35:03 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/01/2020 21:35:06 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/01/2020 21:35:06 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:35:09 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/01/2020 21:35:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:35:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/01/2020 21:35:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:35:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/01/2020 21:35:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:35:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/01/2020 21:35:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:35:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/01/2020 21:35:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:35:09 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/01/2020 21:35:09 - INFO - __main__ -  483 -   Writing example 0 of 12
11/01/2020 21:35:09 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:35:09 - INFO - __main__ -  550 -   guid: dev-1
11/01/2020 21:35:09 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/01/2020 21:35:09 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:35:09 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:35:09 - INFO - __main__ -  550 -   guid: dev-2
11/01/2020 21:35:09 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/01/2020 21:35:09 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:35:09 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:35:09 - INFO - __main__ -  550 -   guid: dev-3
11/01/2020 21:35:09 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/01/2020 21:35:09 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:35:09 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:35:09 - INFO - __main__ -  550 -   guid: dev-4
11/01/2020 21:35:09 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/01/2020 21:35:09 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:35:09 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:35:09 - INFO - __main__ -  550 -   guid: dev-5
11/01/2020 21:35:09 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/01/2020 21:35:09 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:35:09 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:35:09 - INFO - __main__ -  1087 -   ***** Running evaluation *****
11/01/2020 21:35:09 - INFO - __main__ -  1088 -     Num examples = 12
11/01/2020 21:35:09 - INFO - __main__ -  1089 -     Batch size = 8
11/01/2020 21:37:09 - INFO - __main__ -  845 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 21:37:20 - INFO - __main__ -  845 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 21:37:23 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 21:37:23 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 21:37:23 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:37:23 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 21:37:23 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:37:23 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 21:37:23 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:37:23 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 21:37:23 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:37:23 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 21:37:23 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:37:23 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 21:37:27 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 21:37:27 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpufqgss_t
11/01/2020 21:37:31 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:37:33 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 21:37:33 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 21:37:33 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 21:37:33 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:37:33 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 21:37:33 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 21:37:33 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:37:33 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:37:33 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 21:37:33 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 21:37:33 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:37:33 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:37:33 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 21:37:33 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 21:37:33 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:37:33 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:37:33 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 21:37:33 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 21:37:33 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:37:33 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:37:33 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 21:37:33 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 21:37:33 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:37:33 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:37:33 - INFO - __main__ -  951 -   ***** Running training *****
11/01/2020 21:37:33 - INFO - __main__ -  952 -     Num examples = 18
11/01/2020 21:37:33 - INFO - __main__ -  953 -     Batch size = 16
11/01/2020 21:37:33 - INFO - __main__ -  954 -     Num steps = 2
11/01/2020 21:37:55 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/01/2020 21:37:57 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/01/2020 21:37:57 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:38:00 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/01/2020 21:38:00 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:38:00 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/01/2020 21:38:00 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:38:00 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/01/2020 21:38:00 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:38:00 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/01/2020 21:38:00 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:38:00 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/01/2020 21:38:00 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:38:00 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/01/2020 21:38:00 - INFO - __main__ -  483 -   Writing example 0 of 12
11/01/2020 21:38:00 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:38:00 - INFO - __main__ -  550 -   guid: dev-1
11/01/2020 21:38:00 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/01/2020 21:38:00 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:38:00 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:38:00 - INFO - __main__ -  550 -   guid: dev-2
11/01/2020 21:38:00 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/01/2020 21:38:00 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:38:00 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:38:00 - INFO - __main__ -  550 -   guid: dev-3
11/01/2020 21:38:00 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/01/2020 21:38:00 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:38:00 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:38:00 - INFO - __main__ -  550 -   guid: dev-4
11/01/2020 21:38:00 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/01/2020 21:38:00 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:38:00 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:38:00 - INFO - __main__ -  550 -   guid: dev-5
11/01/2020 21:38:00 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/01/2020 21:38:00 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:38:00 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:38:00 - INFO - __main__ -  1088 -   ***** Running evaluation *****
11/01/2020 21:38:00 - INFO - __main__ -  1089 -     Num examples = 12
11/01/2020 21:38:00 - INFO - __main__ -  1090 -     Batch size = 8
11/01/2020 21:41:36 - INFO - __main__ -  849 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 21:41:57 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 21:41:57 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 21:41:57 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:41:57 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 21:41:57 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:41:57 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 21:41:57 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:41:57 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 21:41:57 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:41:57 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 21:41:57 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:41:57 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 21:42:18 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 21:42:18 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpu4962uaj
11/01/2020 21:42:23 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:42:26 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 21:42:26 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 21:42:26 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 21:42:26 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:42:26 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 21:42:26 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 21:42:26 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:42:26 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:42:26 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 21:42:26 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 21:42:26 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:42:26 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:42:26 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 21:42:26 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 21:42:26 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:42:26 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:42:26 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 21:42:26 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 21:42:26 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:42:26 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:42:26 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 21:42:26 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 21:42:26 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:26 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:42:26 - INFO - __main__ -  955 -   ***** Running training *****
11/01/2020 21:42:26 - INFO - __main__ -  956 -     Num examples = 18
11/01/2020 21:42:26 - INFO - __main__ -  957 -     Batch size = 16
11/01/2020 21:42:26 - INFO - __main__ -  958 -     Num steps = 2
11/01/2020 21:42:48 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/01/2020 21:42:51 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/01/2020 21:42:51 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:42:54 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/01/2020 21:42:54 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:42:54 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/01/2020 21:42:54 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:42:54 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/01/2020 21:42:54 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:42:54 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/01/2020 21:42:54 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:42:54 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/01/2020 21:42:54 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:42:54 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/01/2020 21:42:54 - INFO - __main__ -  483 -   Writing example 0 of 12
11/01/2020 21:42:54 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:42:54 - INFO - __main__ -  550 -   guid: dev-1
11/01/2020 21:42:54 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/01/2020 21:42:54 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:42:54 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:42:54 - INFO - __main__ -  550 -   guid: dev-2
11/01/2020 21:42:54 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/01/2020 21:42:54 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:42:54 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:42:54 - INFO - __main__ -  550 -   guid: dev-3
11/01/2020 21:42:54 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/01/2020 21:42:54 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:42:54 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:42:54 - INFO - __main__ -  550 -   guid: dev-4
11/01/2020 21:42:54 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/01/2020 21:42:54 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:42:54 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:42:54 - INFO - __main__ -  550 -   guid: dev-5
11/01/2020 21:42:54 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/01/2020 21:42:54 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:42:54 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:42:54 - INFO - __main__ -  1092 -   ***** Running evaluation *****
11/01/2020 21:42:54 - INFO - __main__ -  1093 -     Num examples = 12
11/01/2020 21:42:54 - INFO - __main__ -  1094 -     Batch size = 8
11/01/2020 21:45:05 - INFO - __main__ -  849 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 21:45:09 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 21:45:09 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 21:45:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:45:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 21:45:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:45:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 21:45:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:45:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 21:45:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:45:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 21:45:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:45:09 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 21:45:11 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 21:45:11 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpgqtpq83c
11/01/2020 21:45:18 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:45:20 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 21:45:20 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 21:45:20 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 21:45:20 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:45:20 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 21:45:20 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 21:45:20 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:45:20 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:45:20 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 21:45:20 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 21:45:20 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:45:20 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:45:20 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 21:45:20 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 21:45:20 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:45:20 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:45:20 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 21:45:20 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 21:45:20 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:45:20 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:45:20 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 21:45:20 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 21:45:20 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:20 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:45:20 - INFO - __main__ -  955 -   ***** Running training *****
11/01/2020 21:45:20 - INFO - __main__ -  956 -     Num examples = 18
11/01/2020 21:45:20 - INFO - __main__ -  957 -     Batch size = 16
11/01/2020 21:45:20 - INFO - __main__ -  958 -     Num steps = 2
11/01/2020 21:45:42 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/01/2020 21:45:44 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/01/2020 21:45:44 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:45:47 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/01/2020 21:45:47 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:45:47 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/01/2020 21:45:47 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:45:47 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/01/2020 21:45:47 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:45:47 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/01/2020 21:45:47 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:45:47 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/01/2020 21:45:47 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:45:47 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/01/2020 21:45:47 - INFO - __main__ -  483 -   Writing example 0 of 12
11/01/2020 21:45:47 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:45:47 - INFO - __main__ -  550 -   guid: dev-1
11/01/2020 21:45:47 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/01/2020 21:45:47 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:45:47 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:45:47 - INFO - __main__ -  550 -   guid: dev-2
11/01/2020 21:45:47 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/01/2020 21:45:47 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:45:47 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:45:47 - INFO - __main__ -  550 -   guid: dev-3
11/01/2020 21:45:47 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/01/2020 21:45:47 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:45:47 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:45:47 - INFO - __main__ -  550 -   guid: dev-4
11/01/2020 21:45:47 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/01/2020 21:45:47 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:45:47 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:45:47 - INFO - __main__ -  550 -   guid: dev-5
11/01/2020 21:45:47 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/01/2020 21:45:47 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:45:47 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:45:47 - INFO - __main__ -  1092 -   ***** Running evaluation *****
11/01/2020 21:45:47 - INFO - __main__ -  1093 -     Num examples = 12
11/01/2020 21:45:47 - INFO - __main__ -  1094 -     Batch size = 8
11/01/2020 21:46:53 - INFO - __main__ -  849 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 21:47:15 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 21:47:16 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 21:47:16 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:47:16 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 21:47:16 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:47:16 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 21:47:16 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:47:16 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 21:47:16 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:47:16 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 21:47:16 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:47:16 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 21:48:04 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 21:48:04 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmp11pqkkkh
11/01/2020 21:48:08 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:48:11 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 21:48:11 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 21:48:11 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 21:48:11 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:48:11 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 21:48:11 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 21:48:11 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:48:11 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:48:11 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 21:48:11 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 21:48:11 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:48:11 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:48:11 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 21:48:11 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 21:48:11 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:48:11 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:48:11 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 21:48:11 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 21:48:11 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:48:11 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:48:11 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 21:48:11 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 21:48:11 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:11 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:48:11 - INFO - __main__ -  955 -   ***** Running training *****
11/01/2020 21:48:11 - INFO - __main__ -  956 -     Num examples = 18
11/01/2020 21:48:11 - INFO - __main__ -  957 -     Batch size = 16
11/01/2020 21:48:11 - INFO - __main__ -  958 -     Num steps = 2
11/01/2020 21:48:33 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/01/2020 21:48:36 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/01/2020 21:48:36 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:48:39 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/01/2020 21:48:39 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:48:39 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/01/2020 21:48:39 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:48:39 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/01/2020 21:48:39 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:48:39 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/01/2020 21:48:39 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:48:39 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/01/2020 21:48:39 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:48:39 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/01/2020 21:48:39 - INFO - __main__ -  483 -   Writing example 0 of 12
11/01/2020 21:48:39 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:48:39 - INFO - __main__ -  550 -   guid: dev-1
11/01/2020 21:48:39 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/01/2020 21:48:39 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:48:39 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:48:39 - INFO - __main__ -  550 -   guid: dev-2
11/01/2020 21:48:39 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/01/2020 21:48:39 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:48:39 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:48:39 - INFO - __main__ -  550 -   guid: dev-3
11/01/2020 21:48:39 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/01/2020 21:48:39 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:48:39 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:48:39 - INFO - __main__ -  550 -   guid: dev-4
11/01/2020 21:48:39 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/01/2020 21:48:39 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:48:39 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:48:39 - INFO - __main__ -  550 -   guid: dev-5
11/01/2020 21:48:39 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/01/2020 21:48:39 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:48:39 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:48:39 - INFO - __main__ -  1092 -   ***** Running evaluation *****
11/01/2020 21:48:39 - INFO - __main__ -  1093 -     Num examples = 12
11/01/2020 21:48:39 - INFO - __main__ -  1094 -     Batch size = 8
11/01/2020 21:50:40 - INFO - __main__ -  1172 -   ***** Eval results *****
11/01/2020 21:50:40 - INFO - __main__ -  1174 -     acc = {'acc': 0.5833333333333334, 'm_f1': 0.5804195804195804, 'w_f1': 0.5687645687645687}
11/01/2020 21:50:40 - INFO - __main__ -  1174 -     eval_loss = 0.7921589612960815
11/01/2020 21:50:40 - INFO - __main__ -  1174 -     global_step = 4
11/01/2020 21:50:40 - INFO - __main__ -  1174 -     loss = 0.2999415844678879
11/01/2020 21:54:15 - INFO - __main__ -  851 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 21:55:08 - INFO - __main__ -  850 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 21:55:11 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 21:55:11 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 21:55:11 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:55:11 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 21:55:11 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:55:11 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 21:55:11 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:55:11 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By pouring the water and salt into the thing, and letting the water evaporate.] label: [correct]
11/01/2020 21:55:11 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:55:11 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By slowly pouring it in a tray.] label: [incorrect]
11/01/2020 21:55:11 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:55:11 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated so there was only salt left.] label: [correct]
11/01/2020 21:55:13 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 21:55:13 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmp_d4xa2sa
11/01/2020 21:55:18 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:55:21 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 21:55:21 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 21:55:21 - INFO - __main__ -  483 -   Writing example 0 of 18
11/01/2020 21:55:21 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:55:21 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 21:55:21 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 21:55:21 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:55:21 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:55:21 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 21:55:21 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 21:55:21 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:55:21 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:55:21 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 21:55:21 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by pouring the water and salt into the thing , and letting the water eva ##por ##ate . [SEP]
11/01/2020 21:55:21 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 13053 1996 2300 1998 5474 2046 1996 2518 1010 1998 5599 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:55:21 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:55:21 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 21:55:21 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by slowly pouring it in a tray . [SEP]
11/01/2020 21:55:21 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 3254 13053 2009 1999 1037 11851 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:55:21 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:55:21 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 21:55:21 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated so there was only salt left . [SEP]
11/01/2020 21:55:21 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 2061 2045 2001 2069 5474 2187 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:21 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:55:21 - INFO - __main__ -  956 -   ***** Running training *****
11/01/2020 21:55:21 - INFO - __main__ -  957 -     Num examples = 18
11/01/2020 21:55:21 - INFO - __main__ -  958 -     Batch size = 16
11/01/2020 21:55:21 - INFO - __main__ -  959 -     Num steps = 2
11/01/2020 21:55:43 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/01/2020 21:55:46 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/01/2020 21:55:46 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 21:55:49 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/01/2020 21:55:49 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:55:49 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/01/2020 21:55:49 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:55:49 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/01/2020 21:55:49 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:55:49 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/01/2020 21:55:49 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:55:49 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/01/2020 21:55:49 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 21:55:49 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/01/2020 21:55:49 - INFO - __main__ -  483 -   Writing example 0 of 12
11/01/2020 21:55:49 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:55:49 - INFO - __main__ -  550 -   guid: dev-1
11/01/2020 21:55:49 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/01/2020 21:55:49 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:55:49 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:55:49 - INFO - __main__ -  550 -   guid: dev-2
11/01/2020 21:55:49 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/01/2020 21:55:49 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 21:55:49 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:55:49 - INFO - __main__ -  550 -   guid: dev-3
11/01/2020 21:55:49 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/01/2020 21:55:49 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:55:49 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:55:49 - INFO - __main__ -  550 -   guid: dev-4
11/01/2020 21:55:49 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/01/2020 21:55:49 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:55:49 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 21:55:49 - INFO - __main__ -  550 -   guid: dev-5
11/01/2020 21:55:49 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/01/2020 21:55:49 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 21:55:49 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 21:55:49 - INFO - __main__ -  1093 -   ***** Running evaluation *****
11/01/2020 21:55:49 - INFO - __main__ -  1094 -     Num examples = 12
11/01/2020 21:55:49 - INFO - __main__ -  1095 -     Batch size = 8
11/01/2020 22:03:38 - INFO - __main__ -  1173 -   ***** Eval results *****
11/01/2020 22:03:38 - INFO - __main__ -  1175 -     acc = {'acc': 0.5833333333333334, 'm_f1': 0.5804195804195804, 'w_f1': 0.5687645687645687}
11/01/2020 22:03:38 - INFO - __main__ -  1175 -     eval_loss = 0.7921589612960815
11/01/2020 22:03:38 - INFO - __main__ -  1175 -     global_step = 4
11/01/2020 22:03:38 - INFO - __main__ -  1175 -     loss = 0.2999415844678879
11/01/2020 22:16:48 - INFO - __main__ -  848 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 22:17:17 - INFO - __main__ -  848 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/01/2020 22:17:18 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/01/2020 22:17:18 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/01/2020 22:17:18 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 22:17:18 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/01/2020 22:17:18 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 22:17:18 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/01/2020 22:17:18 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 22:17:18 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/01/2020 22:17:18 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 22:17:18 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/01/2020 22:17:18 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 22:17:18 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/01/2020 22:17:19 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/01/2020 22:17:19 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmp5gukg45u
11/01/2020 22:17:23 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 22:17:26 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/01/2020 22:17:26 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/01/2020 22:17:26 - INFO - __main__ -  483 -   Writing example 0 of 4969
11/01/2020 22:17:26 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 22:17:26 - INFO - __main__ -  550 -   guid: train-1
11/01/2020 22:17:26 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/01/2020 22:17:26 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 22:17:26 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 22:17:26 - INFO - __main__ -  550 -   guid: train-2
11/01/2020 22:17:26 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/01/2020 22:17:26 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 22:17:26 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 22:17:26 - INFO - __main__ -  550 -   guid: train-3
11/01/2020 22:17:26 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/01/2020 22:17:26 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 22:17:26 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 22:17:26 - INFO - __main__ -  550 -   guid: train-4
11/01/2020 22:17:26 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/01/2020 22:17:26 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 22:17:26 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 22:17:26 - INFO - __main__ -  550 -   guid: train-5
11/01/2020 22:17:26 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/01/2020 22:17:26 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 22:17:26 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 22:17:28 - INFO - __main__ -  954 -   ***** Running training *****
11/01/2020 22:17:28 - INFO - __main__ -  955 -     Num examples = 4969
11/01/2020 22:17:28 - INFO - __main__ -  956 -     Batch size = 16
11/01/2020 22:17:28 - INFO - __main__ -  957 -     Num steps = 310
11/01/2020 23:02:58 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/01/2020 23:02:58 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/01/2020 23:03:00 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/01/2020 23:03:01 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 23:03:01 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/01/2020 23:03:01 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 23:03:01 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/01/2020 23:03:01 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 23:03:01 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/01/2020 23:03:01 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 23:03:01 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/01/2020 23:03:01 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/01/2020 23:03:01 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/01/2020 23:03:01 - INFO - __main__ -  483 -   Writing example 0 of 540
11/01/2020 23:03:01 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 23:03:01 - INFO - __main__ -  550 -   guid: dev-1
11/01/2020 23:03:01 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/01/2020 23:03:01 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 23:03:01 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 23:03:01 - INFO - __main__ -  550 -   guid: dev-2
11/01/2020 23:03:01 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/01/2020 23:03:01 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  557 -   label: correct (id = 0)
11/01/2020 23:03:01 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 23:03:01 - INFO - __main__ -  550 -   guid: dev-3
11/01/2020 23:03:01 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/01/2020 23:03:01 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 23:03:01 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 23:03:01 - INFO - __main__ -  550 -   guid: dev-4
11/01/2020 23:03:01 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/01/2020 23:03:01 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 23:03:01 - INFO - __main__ -  549 -   *** Example ***
11/01/2020 23:03:01 - INFO - __main__ -  550 -   guid: dev-5
11/01/2020 23:03:01 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/01/2020 23:03:01 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/01/2020 23:03:01 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/01/2020 23:03:01 - INFO - __main__ -  1091 -   ***** Running evaluation *****
11/01/2020 23:03:01 - INFO - __main__ -  1092 -     Num examples = 540
11/01/2020 23:03:01 - INFO - __main__ -  1093 -     Batch size = 8
11/02/2020 11:14:22 - INFO - __main__ -  848 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/02/2020 11:14:35 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/02/2020 11:14:36 - INFO - __main__ -  174 -   LOOKING AT E:\project\EAAI-25-master\traindata/sciEntsBank/A-origin\2way\train.txt
11/02/2020 11:14:36 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/02/2020 11:14:36 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/02/2020 11:14:36 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/02/2020 11:14:36 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/02/2020 11:14:36 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/02/2020 11:14:36 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/02/2020 11:14:36 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/02/2020 11:14:36 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/02/2020 11:14:36 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/02/2020 11:14:36 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/02/2020 11:14:59 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/02/2020 11:14:59 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpu5fg0clm
11/02/2020 11:15:03 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/02/2020 11:15:06 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/02/2020 11:15:06 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/02/2020 11:15:06 - INFO - __main__ -  483 -   Writing example 0 of 4969
11/02/2020 11:15:06 - INFO - __main__ -  549 -   *** Example ***
11/02/2020 11:15:06 - INFO - __main__ -  550 -   guid: train-1
11/02/2020 11:15:06 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/02/2020 11:15:06 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/02/2020 11:15:06 - INFO - __main__ -  549 -   *** Example ***
11/02/2020 11:15:06 - INFO - __main__ -  550 -   guid: train-2
11/02/2020 11:15:06 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/02/2020 11:15:06 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  557 -   label: correct (id = 0)
11/02/2020 11:15:06 - INFO - __main__ -  549 -   *** Example ***
11/02/2020 11:15:06 - INFO - __main__ -  550 -   guid: train-3
11/02/2020 11:15:06 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/02/2020 11:15:06 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  557 -   label: correct (id = 0)
11/02/2020 11:15:06 - INFO - __main__ -  549 -   *** Example ***
11/02/2020 11:15:06 - INFO - __main__ -  550 -   guid: train-4
11/02/2020 11:15:06 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/02/2020 11:15:06 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/02/2020 11:15:06 - INFO - __main__ -  549 -   *** Example ***
11/02/2020 11:15:06 - INFO - __main__ -  550 -   guid: train-5
11/02/2020 11:15:06 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/02/2020 11:15:06 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 11:15:06 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/02/2020 11:15:08 - INFO - __main__ -  954 -   ***** Running training *****
11/02/2020 11:15:08 - INFO - __main__ -  955 -     Num examples = 4969
11/02/2020 11:15:08 - INFO - __main__ -  956 -     Batch size = 16
11/02/2020 11:15:08 - INFO - __main__ -  957 -     Num steps = 310
11/02/2020 12:01:00 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/02/2020 12:01:00 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/02/2020 12:01:02 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/02/2020 12:01:02 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/02/2020 12:01:02 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/02/2020 12:01:02 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/02/2020 12:01:02 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/02/2020 12:01:02 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/02/2020 12:01:02 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/02/2020 12:01:02 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/02/2020 12:01:02 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/02/2020 12:01:02 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/02/2020 12:01:02 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/02/2020 12:01:02 - INFO - __main__ -  483 -   Writing example 0 of 540
11/02/2020 12:01:02 - INFO - __main__ -  549 -   *** Example ***
11/02/2020 12:01:02 - INFO - __main__ -  550 -   guid: dev-1
11/02/2020 12:01:02 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/02/2020 12:01:02 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  557 -   label: correct (id = 0)
11/02/2020 12:01:02 - INFO - __main__ -  549 -   *** Example ***
11/02/2020 12:01:02 - INFO - __main__ -  550 -   guid: dev-2
11/02/2020 12:01:02 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/02/2020 12:01:02 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  557 -   label: correct (id = 0)
11/02/2020 12:01:02 - INFO - __main__ -  549 -   *** Example ***
11/02/2020 12:01:02 - INFO - __main__ -  550 -   guid: dev-3
11/02/2020 12:01:02 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/02/2020 12:01:02 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/02/2020 12:01:02 - INFO - __main__ -  549 -   *** Example ***
11/02/2020 12:01:02 - INFO - __main__ -  550 -   guid: dev-4
11/02/2020 12:01:02 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/02/2020 12:01:02 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/02/2020 12:01:02 - INFO - __main__ -  549 -   *** Example ***
11/02/2020 12:01:02 - INFO - __main__ -  550 -   guid: dev-5
11/02/2020 12:01:02 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/02/2020 12:01:02 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/02/2020 12:01:02 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/02/2020 12:01:02 - INFO - __main__ -  1091 -   ***** Running evaluation *****
11/02/2020 12:01:02 - INFO - __main__ -  1092 -     Num examples = 540
11/02/2020 12:01:02 - INFO - __main__ -  1093 -     Batch size = 8
11/02/2020 14:31:33 - INFO - __main__ -  1171 -   ***** Eval results *****
11/02/2020 14:31:33 - INFO - __main__ -  1173 -     acc = {'acc': 0.7444444444444445, 'm_f1': 0.730218952734013, 'w_f1': 0.738708359077335}
11/02/2020 14:31:33 - INFO - __main__ -  1173 -     eval_loss = 0.5224287784932291
11/02/2020 14:31:33 - INFO - __main__ -  1173 -     global_step = 311
11/02/2020 14:31:33 - INFO - __main__ -  1173 -     loss = 0.569947986357465
11/04/2020 12:02:57 - INFO - __main__ -  831 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/04/2020 12:03:17 - INFO - __main__ -  831 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/04/2020 12:03:38 - INFO - pytorch_pretrained_bert.file_utils -  233 -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to C:\Users\lgy\AppData\Local\Temp\tmpiiewbl5m
11/08/2020 16:53:50 - INFO - __main__ -  831 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/08/2020 16:53:55 - INFO - pytorch_pretrained_bert.file_utils -  233 -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to C:\Users\lgy\AppData\Local\Temp\tmpe4fpaceo
11/08/2020 16:53:57 - INFO - pytorch_pretrained_bert.file_utils -  246 -   copying C:\Users\lgy\AppData\Local\Temp\tmpe4fpaceo to cache at C:\Users\lgy\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb
11/08/2020 16:53:57 - INFO - pytorch_pretrained_bert.file_utils -  250 -   creating metadata file for C:\Users\lgy\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb
11/08/2020 16:53:57 - INFO - pytorch_pretrained_bert.file_utils -  259 -   removing temp file C:\Users\lgy\AppData\Local\Temp\tmpe4fpaceo
11/08/2020 16:53:57 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\lgy\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb
11/08/2020 16:53:58 - INFO - __main__ -  174 -   LOOKING AT D:\PythonProject\my-EAAI-25-master/traindata/sciEntsBank/B4-replace-A-B1\2way\train.txt
11/08/2020 16:53:58 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/08/2020 16:53:58 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/08/2020 16:53:58 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/08/2020 16:53:58 - INFO - __main__ -  199 -   text_a: [Water evaporated and left salt.] test_b: [Let me sit on a plate a day.] label: [incorrect]
11/08/2020 16:53:58 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/08/2020 16:53:58 - INFO - __main__ -  199 -   text_a: [Water evaporated and left salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/08/2020 16:53:58 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/08/2020 16:53:58 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let me sit on a plate a day.] label: [incorrect]
11/08/2020 16:53:58 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/08/2020 16:53:58 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/08/2020 16:53:59 - INFO - pytorch_pretrained_bert.file_utils -  233 -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to C:\Users\lgy\AppData\Local\Temp\tmpw3dprr2v
11/08/2020 16:57:42 - INFO - pytorch_pretrained_bert.file_utils -  246 -   copying C:\Users\lgy\AppData\Local\Temp\tmpw3dprr2v to cache at C:\Users\lgy\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/08/2020 16:57:43 - INFO - pytorch_pretrained_bert.file_utils -  250 -   creating metadata file for C:\Users\lgy\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/08/2020 16:57:43 - INFO - pytorch_pretrained_bert.file_utils -  259 -   removing temp file C:\Users\lgy\AppData\Local\Temp\tmpw3dprr2v
11/08/2020 16:57:43 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\lgy\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/08/2020 16:57:43 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\lgy\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\lgy\AppData\Local\Temp\tmpgmyqm0tc
11/08/2020 16:57:46 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/08/2020 16:57:48 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/08/2020 16:57:48 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/08/2020 16:57:48 - INFO - __main__ -  483 -   Writing example 0 of 19740
11/08/2020 16:57:48 - INFO - __main__ -  549 -   *** Example ***
11/08/2020 16:57:48 - INFO - __main__ -  550 -   guid: train-1
11/08/2020 16:57:48 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/08/2020 16:57:48 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/08/2020 16:57:48 - INFO - __main__ -  549 -   *** Example ***
11/08/2020 16:57:48 - INFO - __main__ -  550 -   guid: train-2
11/08/2020 16:57:48 - INFO - __main__ -  552 -   tokens: [CLS] water eva ##por ##ated and left salt . [SEP] let me sit on a plate a day . [SEP]
11/08/2020 16:57:48 - INFO - __main__ -  553 -   input_ids: 101 2300 9345 17822 4383 1998 2187 5474 1012 102 2292 2033 4133 2006 1037 5127 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/08/2020 16:57:48 - INFO - __main__ -  549 -   *** Example ***
11/08/2020 16:57:48 - INFO - __main__ -  550 -   guid: train-3
11/08/2020 16:57:48 - INFO - __main__ -  552 -   tokens: [CLS] water eva ##por ##ated and left salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/08/2020 16:57:48 - INFO - __main__ -  553 -   input_ids: 101 2300 9345 17822 4383 1998 2187 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/08/2020 16:57:48 - INFO - __main__ -  549 -   *** Example ***
11/08/2020 16:57:48 - INFO - __main__ -  550 -   guid: train-4
11/08/2020 16:57:48 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let me sit on a plate a day . [SEP]
11/08/2020 16:57:48 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 2033 4133 2006 1037 5127 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/08/2020 16:57:48 - INFO - __main__ -  549 -   *** Example ***
11/08/2020 16:57:48 - INFO - __main__ -  550 -   guid: train-5
11/08/2020 16:57:48 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/08/2020 16:57:48 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:48 - INFO - __main__ -  557 -   label: correct (id = 0)
11/08/2020 16:57:51 - INFO - __main__ -  483 -   Writing example 10000 of 19740
11/08/2020 16:57:55 - INFO - __main__ -  937 -   ***** Running training *****
11/08/2020 16:57:55 - INFO - __main__ -  938 -     Num examples = 19740
11/08/2020 16:57:55 - INFO - __main__ -  939 -     Batch size = 16
11/08/2020 16:57:55 - INFO - __main__ -  940 -     Num steps = 3699
11/08/2020 16:57:55 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/08/2020 16:57:55 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/08/2020 16:57:55 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/08/2020 16:57:55 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/08/2020 16:57:55 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/08/2020 16:57:55 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/08/2020 16:57:55 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/08/2020 16:57:55 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/08/2020 16:57:55 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/08/2020 16:57:55 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/08/2020 16:57:55 - INFO - __main__ -  483 -   Writing example 0 of 540
11/08/2020 16:57:55 - INFO - __main__ -  549 -   *** Example ***
11/08/2020 16:57:55 - INFO - __main__ -  550 -   guid: dev-1
11/08/2020 16:57:55 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/08/2020 16:57:55 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  557 -   label: correct (id = 0)
11/08/2020 16:57:55 - INFO - __main__ -  549 -   *** Example ***
11/08/2020 16:57:55 - INFO - __main__ -  550 -   guid: dev-2
11/08/2020 16:57:55 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/08/2020 16:57:55 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  557 -   label: correct (id = 0)
11/08/2020 16:57:55 - INFO - __main__ -  549 -   *** Example ***
11/08/2020 16:57:55 - INFO - __main__ -  550 -   guid: dev-3
11/08/2020 16:57:55 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/08/2020 16:57:55 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/08/2020 16:57:55 - INFO - __main__ -  549 -   *** Example ***
11/08/2020 16:57:55 - INFO - __main__ -  550 -   guid: dev-4
11/08/2020 16:57:55 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/08/2020 16:57:55 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/08/2020 16:57:55 - INFO - __main__ -  549 -   *** Example ***
11/08/2020 16:57:55 - INFO - __main__ -  550 -   guid: dev-5
11/08/2020 16:57:55 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/08/2020 16:57:55 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/08/2020 16:57:55 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/08/2020 16:57:55 - INFO - __main__ -  969 -   ***** Running evaluation *****
11/08/2020 16:57:55 - INFO - __main__ -  970 -     Num examples = 540
11/08/2020 16:57:55 - INFO - __main__ -  971 -     Batch size = 8
11/10/2020 21:30:53 - INFO - __main__ -  831 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/10/2020 21:30:53 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/10/2020 21:30:53 - INFO - __main__ -  174 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/10/2020 21:30:53 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/10/2020 21:30:53 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/10/2020 21:30:53 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/10/2020 21:30:53 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/10/2020 21:30:53 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/10/2020 21:30:53 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/10/2020 21:30:53 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/10/2020 21:30:53 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/10/2020 21:30:53 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/10/2020 21:30:53 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/10/2020 21:30:53 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/10/2020 21:30:53 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpwc5e72x6
11/10/2020 21:31:02 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/10/2020 21:31:07 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/10/2020 21:31:07 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/10/2020 21:31:07 - INFO - __main__ -  483 -   Writing example 0 of 4969
11/10/2020 21:31:07 - INFO - __main__ -  549 -   *** Example ***
11/10/2020 21:31:07 - INFO - __main__ -  550 -   guid: train-1
11/10/2020 21:31:07 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/10/2020 21:31:07 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/10/2020 21:31:07 - INFO - __main__ -  549 -   *** Example ***
11/10/2020 21:31:07 - INFO - __main__ -  550 -   guid: train-2
11/10/2020 21:31:07 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/10/2020 21:31:07 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  557 -   label: correct (id = 0)
11/10/2020 21:31:07 - INFO - __main__ -  549 -   *** Example ***
11/10/2020 21:31:07 - INFO - __main__ -  550 -   guid: train-3
11/10/2020 21:31:07 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/10/2020 21:31:07 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  557 -   label: correct (id = 0)
11/10/2020 21:31:07 - INFO - __main__ -  549 -   *** Example ***
11/10/2020 21:31:07 - INFO - __main__ -  550 -   guid: train-4
11/10/2020 21:31:07 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/10/2020 21:31:07 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/10/2020 21:31:07 - INFO - __main__ -  549 -   *** Example ***
11/10/2020 21:31:07 - INFO - __main__ -  550 -   guid: train-5
11/10/2020 21:31:07 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/10/2020 21:31:07 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:07 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/10/2020 21:31:09 - INFO - __main__ -  937 -   ***** Running training *****
11/10/2020 21:31:09 - INFO - __main__ -  938 -     Num examples = 4969
11/10/2020 21:31:09 - INFO - __main__ -  939 -     Batch size = 16
11/10/2020 21:31:09 - INFO - __main__ -  940 -     Num steps = 930
11/10/2020 21:31:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/10/2020 21:31:09 - INFO - __main__ -  199 -   text_a: [10 milliliters to 20 milliliters. The radishes did not grow at all in pots one and 5 so the range of tolerance is for pots 2, 3 and 4, which got 10 to 20 milliliters of water.] test_b: [0 to 25 milliliters, 0 to 25 milliliters because the plants all grew from 0 to 25 milliliters of water.] label: [incorrect]
11/10/2020 21:31:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/10/2020 21:31:09 - INFO - __main__ -  199 -   text_a: [10 milliliters to 20 milliliters. The radishes did not grow at all in pots one and 5 so the range of tolerance is for pots 2, 3 and 4, which got 10 to 20 milliliters of water.] test_b: [10 to 20 milliliters of water. Pot 2, 3, and 4 had been watered between 10 and 20 milliliters of water and they were the only ones that grew.] label: [correct]
11/10/2020 21:31:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/10/2020 21:31:09 - INFO - __main__ -  199 -   text_a: [10 milliliters to 20 milliliters. The radishes did not grow at all in pots one and 5 so the range of tolerance is for pots 2, 3 and 4, which got 10 to 20 milliliters of water.] test_b: [10 to 20 milliliters water, I looked at which plant roots grew.] label: [correct]
11/10/2020 21:31:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/10/2020 21:31:09 - INFO - __main__ -  199 -   text_a: [10 milliliters to 20 milliliters. The radishes did not grow at all in pots one and 5 so the range of tolerance is for pots 2, 3 and 4, which got 10 to 20 milliliters of water.] test_b: [10 to 20 milliliters of water, none grew in one or 5 so those do not count for range of tolerance.] label: [correct]
11/10/2020 21:31:09 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/10/2020 21:31:09 - INFO - __main__ -  199 -   text_a: [10 milliliters to 20 milliliters. The radishes did not grow at all in pots one and 5 so the range of tolerance is for pots 2, 3 and 4, which got 10 to 20 milliliters of water.] test_b: [10 to 20 milliliters, Well in pot one nothing grew same in pot 5 so the one that grew are a range of tolerance form 10 milliliters to 20 milliliters.] label: [correct]
11/10/2020 21:31:09 - INFO - __main__ -  483 -   Writing example 0 of 4562
11/10/2020 21:31:09 - INFO - __main__ -  549 -   *** Example ***
11/10/2020 21:31:09 - INFO - __main__ -  550 -   guid: dev-1
11/10/2020 21:31:09 - INFO - __main__ -  552 -   tokens: [CLS] 10 mill ##ili ##ters to 20 mill ##ili ##ters . the ra ##dis ##hes did not grow at all in pots one and 5 so the range of tolerance is for pots 2 , 3 and 4 , which got 10 to 20 mill ##ili ##ters of water . [SEP] 0 to 25 mill ##ili ##ters , 0 to 25 mill ##ili ##ters because the plants all grew from 0 to 25 mill ##ili ##ters of water . [SEP]
11/10/2020 21:31:09 - INFO - __main__ -  553 -   input_ids: 101 2184 4971 18622 7747 2000 2322 4971 18622 7747 1012 1996 10958 10521 15689 2106 2025 4982 2012 2035 1999 18911 2028 1998 1019 2061 1996 2846 1997 13986 2003 2005 18911 1016 1010 1017 1998 1018 1010 2029 2288 2184 2000 2322 4971 18622 7747 1997 2300 1012 102 1014 2000 2423 4971 18622 7747 1010 1014 2000 2423 4971 18622 7747 2138 1996 4264 2035 3473 2013 1014 2000 2423 4971 18622 7747 1997 2300 1012 102 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:09 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:09 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:09 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/10/2020 21:31:09 - INFO - __main__ -  549 -   *** Example ***
11/10/2020 21:31:09 - INFO - __main__ -  550 -   guid: dev-2
11/10/2020 21:31:09 - INFO - __main__ -  552 -   tokens: [CLS] 10 mill ##ili ##ters to 20 mill ##ili ##ters . the ra ##dis ##hes did not grow at all in pots one and 5 so the range of tolerance is for pots 2 , 3 and 4 , which got 10 to 20 mill ##ili ##ters of water . [SEP] 10 to 20 mill ##ili ##ters of water . pot 2 , 3 , and 4 had been watered between 10 and 20 mill ##ili ##ters of water and they were the only ones that grew . [SEP]
11/10/2020 21:31:09 - INFO - __main__ -  553 -   input_ids: 101 2184 4971 18622 7747 2000 2322 4971 18622 7747 1012 1996 10958 10521 15689 2106 2025 4982 2012 2035 1999 18911 2028 1998 1019 2061 1996 2846 1997 13986 2003 2005 18911 1016 1010 1017 1998 1018 1010 2029 2288 2184 2000 2322 4971 18622 7747 1997 2300 1012 102 2184 2000 2322 4971 18622 7747 1997 2300 1012 8962 1016 1010 1017 1010 1998 1018 2018 2042 27129 2090 2184 1998 2322 4971 18622 7747 1997 2300 1998 2027 2020 1996 2069 3924 2008 3473 1012 102 0
11/10/2020 21:31:09 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
11/10/2020 21:31:09 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
11/10/2020 21:31:09 - INFO - __main__ -  557 -   label: correct (id = 0)
11/10/2020 21:31:09 - INFO - __main__ -  549 -   *** Example ***
11/10/2020 21:31:09 - INFO - __main__ -  550 -   guid: dev-3
11/10/2020 21:31:09 - INFO - __main__ -  552 -   tokens: [CLS] 10 mill ##ili ##ters to 20 mill ##ili ##ters . the ra ##dis ##hes did not grow at all in pots one and 5 so the range of tolerance is for pots 2 , 3 and 4 , which got 10 to 20 mill ##ili ##ters of water . [SEP] 10 to 20 mill ##ili ##ters water , i looked at which plant roots grew . [SEP]
11/10/2020 21:31:09 - INFO - __main__ -  553 -   input_ids: 101 2184 4971 18622 7747 2000 2322 4971 18622 7747 1012 1996 10958 10521 15689 2106 2025 4982 2012 2035 1999 18911 2028 1998 1019 2061 1996 2846 1997 13986 2003 2005 18911 1016 1010 1017 1998 1018 1010 2029 2288 2184 2000 2322 4971 18622 7747 1997 2300 1012 102 2184 2000 2322 4971 18622 7747 2300 1010 1045 2246 2012 2029 3269 6147 3473 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:09 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:09 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:09 - INFO - __main__ -  557 -   label: correct (id = 0)
11/10/2020 21:31:09 - INFO - __main__ -  549 -   *** Example ***
11/10/2020 21:31:09 - INFO - __main__ -  550 -   guid: dev-4
11/10/2020 21:31:09 - INFO - __main__ -  552 -   tokens: [CLS] 10 mill ##ili ##ters to 20 mill ##ili ##ters . the ra ##dis ##hes did not grow at all in pots one and 5 so the range of tolerance is for pots 2 , 3 and 4 , which got 10 to 20 mill ##ili ##ters of water . [SEP] 10 to 20 mill ##ili ##ters of water , none grew in one or 5 so those do not count for range of tolerance . [SEP]
11/10/2020 21:31:09 - INFO - __main__ -  553 -   input_ids: 101 2184 4971 18622 7747 2000 2322 4971 18622 7747 1012 1996 10958 10521 15689 2106 2025 4982 2012 2035 1999 18911 2028 1998 1019 2061 1996 2846 1997 13986 2003 2005 18911 1016 1010 1017 1998 1018 1010 2029 2288 2184 2000 2322 4971 18622 7747 1997 2300 1012 102 2184 2000 2322 4971 18622 7747 1997 2300 1010 3904 3473 1999 2028 2030 1019 2061 2216 2079 2025 4175 2005 2846 1997 13986 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:09 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:09 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
11/10/2020 21:31:09 - INFO - __main__ -  557 -   label: correct (id = 0)
11/10/2020 21:31:09 - INFO - __main__ -  549 -   *** Example ***
11/10/2020 21:31:09 - INFO - __main__ -  550 -   guid: dev-5
11/10/2020 21:31:09 - INFO - __main__ -  552 -   tokens: [CLS] 10 mill ##ili ##ters to 20 mill ##ili ##ters . the ra ##dis ##hes did not grow at all in pots one and 5 so the range of tolerance is for pots 2 , 3 and 4 , which got 10 to 20 mill ##ili ##ters of water . [SEP] 10 to 20 mill ##ili ##ters , well in pot one nothing grew same in pot 5 so the one that grew are a range of tolerance form 10 mill ##ili ##ters to 20 mill ##ili ##ters . [SEP]
11/10/2020 21:31:09 - INFO - __main__ -  553 -   input_ids: 101 2184 4971 18622 7747 2000 2322 4971 18622 7747 1012 1996 10958 10521 15689 2106 2025 4982 2012 2035 1999 18911 2028 1998 1019 2061 1996 2846 1997 13986 2003 2005 18911 1016 1010 1017 1998 1018 1010 2029 2288 2184 2000 2322 4971 18622 7747 1997 2300 1012 102 2184 2000 2322 4971 18622 7747 1010 2092 1999 8962 2028 2498 3473 2168 1999 8962 1019 2061 1996 2028 2008 3473 2024 1037 2846 1997 13986 2433 2184 4971 18622 7747 2000 2322 4971 18622 7747 1012 102
11/10/2020 21:31:09 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
11/10/2020 21:31:09 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
11/10/2020 21:31:09 - INFO - __main__ -  557 -   label: correct (id = 0)
11/10/2020 21:31:11 - INFO - __main__ -  969 -   ***** Running evaluation *****
11/10/2020 21:31:11 - INFO - __main__ -  970 -     Num examples = 4562
11/10/2020 21:31:11 - INFO - __main__ -  971 -     Batch size = 8
11/11/2020 00:18:05 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/11/2020 00:18:11 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/11/2020 11:11:13 - INFO - __main__ -  832 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/11/2020 11:11:13 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/11/2020 11:11:13 - INFO - __main__ -  174 -   LOOKING AT F:\PYTHONproject\the-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/11/2020 11:11:13 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 11:11:13 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/11/2020 11:11:13 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 11:11:13 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/11/2020 11:11:13 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 11:11:13 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/11/2020 11:11:13 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 11:11:13 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/11/2020 11:11:13 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 11:11:13 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/11/2020 11:11:13 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/11/2020 11:11:13 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpk9iu_d8i
11/11/2020 11:11:19 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/11/2020 11:11:22 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/11/2020 11:11:22 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/11/2020 11:11:22 - INFO - __main__ -  483 -   Writing example 0 of 4969
11/11/2020 11:11:22 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 11:11:22 - INFO - __main__ -  550 -   guid: train-1
11/11/2020 11:11:22 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/11/2020 11:11:22 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 11:11:22 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 11:11:22 - INFO - __main__ -  550 -   guid: train-2
11/11/2020 11:11:22 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/11/2020 11:11:22 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 11:11:22 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 11:11:22 - INFO - __main__ -  550 -   guid: train-3
11/11/2020 11:11:22 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/11/2020 11:11:22 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 11:11:22 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 11:11:22 - INFO - __main__ -  550 -   guid: train-4
11/11/2020 11:11:22 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/11/2020 11:11:22 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 11:11:22 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 11:11:22 - INFO - __main__ -  550 -   guid: train-5
11/11/2020 11:11:22 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/11/2020 11:11:22 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:11:22 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 11:11:25 - INFO - __main__ -  938 -   ***** Running training *****
11/11/2020 11:11:25 - INFO - __main__ -  939 -     Num examples = 4969
11/11/2020 11:11:25 - INFO - __main__ -  940 -     Batch size = 16
11/11/2020 11:11:25 - INFO - __main__ -  941 -     Num steps = 930
11/11/2020 11:12:25 - INFO - __main__ -  832 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/11/2020 11:12:25 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/11/2020 11:12:25 - INFO - __main__ -  174 -   LOOKING AT F:\PYTHONproject\the-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/11/2020 11:12:25 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 11:12:25 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/11/2020 11:12:25 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 11:12:25 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/11/2020 11:12:25 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 11:12:25 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/11/2020 11:12:25 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 11:12:25 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/11/2020 11:12:25 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 11:12:25 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/11/2020 11:12:25 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/11/2020 11:12:25 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmp2m9s0bfs
11/11/2020 11:12:29 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/11/2020 11:12:32 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/11/2020 11:12:32 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/11/2020 11:12:32 - INFO - __main__ -  483 -   Writing example 0 of 4969
11/11/2020 11:12:32 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 11:12:32 - INFO - __main__ -  550 -   guid: train-1
11/11/2020 11:12:32 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/11/2020 11:12:32 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 11:12:32 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 11:12:32 - INFO - __main__ -  550 -   guid: train-2
11/11/2020 11:12:32 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/11/2020 11:12:32 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 11:12:32 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 11:12:32 - INFO - __main__ -  550 -   guid: train-3
11/11/2020 11:12:32 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/11/2020 11:12:32 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 11:12:32 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 11:12:32 - INFO - __main__ -  550 -   guid: train-4
11/11/2020 11:12:32 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/11/2020 11:12:32 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 11:12:32 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 11:12:32 - INFO - __main__ -  550 -   guid: train-5
11/11/2020 11:12:32 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/11/2020 11:12:32 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 11:12:32 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 11:12:35 - INFO - __main__ -  938 -   ***** Running training *****
11/11/2020 11:12:35 - INFO - __main__ -  939 -     Num examples = 4969
11/11/2020 11:12:35 - INFO - __main__ -  940 -     Batch size = 16
11/11/2020 11:12:35 - INFO - __main__ -  941 -     Num steps = 930
11/11/2020 13:39:54 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/11/2020 13:40:01 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/11/2020 13:40:03 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/11/2020 13:40:04 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/11/2020 13:40:06 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/11/2020 13:40:06 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 13:40:06 - INFO - __main__ -  199 -   text_a: [10 milliliters to 20 milliliters. The radishes did not grow at all in pots one and 5 so the range of tolerance is for pots 2, 3 and 4, which got 10 to 20 milliliters of water.] test_b: [0 to 25 milliliters, 0 to 25 milliliters because the plants all grew from 0 to 25 milliliters of water.] label: [incorrect]
11/11/2020 13:40:06 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 13:40:06 - INFO - __main__ -  199 -   text_a: [10 milliliters to 20 milliliters. The radishes did not grow at all in pots one and 5 so the range of tolerance is for pots 2, 3 and 4, which got 10 to 20 milliliters of water.] test_b: [10 to 20 milliliters of water. Pot 2, 3, and 4 had been watered between 10 and 20 milliliters of water and they were the only ones that grew.] label: [correct]
11/11/2020 13:40:06 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 13:40:06 - INFO - __main__ -  199 -   text_a: [10 milliliters to 20 milliliters. The radishes did not grow at all in pots one and 5 so the range of tolerance is for pots 2, 3 and 4, which got 10 to 20 milliliters of water.] test_b: [10 to 20 milliliters water, I looked at which plant roots grew.] label: [correct]
11/11/2020 13:40:06 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 13:40:06 - INFO - __main__ -  199 -   text_a: [10 milliliters to 20 milliliters. The radishes did not grow at all in pots one and 5 so the range of tolerance is for pots 2, 3 and 4, which got 10 to 20 milliliters of water.] test_b: [10 to 20 milliliters of water, none grew in one or 5 so those do not count for range of tolerance.] label: [correct]
11/11/2020 13:40:06 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 13:40:06 - INFO - __main__ -  199 -   text_a: [10 milliliters to 20 milliliters. The radishes did not grow at all in pots one and 5 so the range of tolerance is for pots 2, 3 and 4, which got 10 to 20 milliliters of water.] test_b: [10 to 20 milliliters, Well in pot one nothing grew same in pot 5 so the one that grew are a range of tolerance form 10 milliliters to 20 milliliters.] label: [correct]
11/11/2020 13:40:06 - INFO - __main__ -  483 -   Writing example 0 of 4562
11/11/2020 13:40:06 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 13:40:06 - INFO - __main__ -  550 -   guid: dev-1
11/11/2020 13:40:06 - INFO - __main__ -  552 -   tokens: [CLS] 10 mill ##ili ##ters to 20 mill ##ili ##ters . the ra ##dis ##hes did not grow at all in pots one and 5 so the range of tolerance is for pots 2 , 3 and 4 , which got 10 to 20 mill ##ili ##ters of water . [SEP] 0 to 25 mill ##ili ##ters , 0 to 25 mill ##ili ##ters because the plants all grew from 0 to 25 mill ##ili ##ters of water . [SEP]
11/11/2020 13:40:06 - INFO - __main__ -  553 -   input_ids: 101 2184 4971 18622 7747 2000 2322 4971 18622 7747 1012 1996 10958 10521 15689 2106 2025 4982 2012 2035 1999 18911 2028 1998 1019 2061 1996 2846 1997 13986 2003 2005 18911 1016 1010 1017 1998 1018 1010 2029 2288 2184 2000 2322 4971 18622 7747 1997 2300 1012 102 1014 2000 2423 4971 18622 7747 1010 1014 2000 2423 4971 18622 7747 2138 1996 4264 2035 3473 2013 1014 2000 2423 4971 18622 7747 1997 2300 1012 102 0 0 0 0 0 0 0 0 0 0
11/11/2020 13:40:06 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
11/11/2020 13:40:06 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0
11/11/2020 13:40:06 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 13:40:06 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 13:40:06 - INFO - __main__ -  550 -   guid: dev-2
11/11/2020 13:40:06 - INFO - __main__ -  552 -   tokens: [CLS] 10 mill ##ili ##ters to 20 mill ##ili ##ters . the ra ##dis ##hes did not grow at all in pots one and 5 so the range of tolerance is for pots 2 , 3 and 4 , which got 10 to 20 mill ##ili ##ters of water . [SEP] 10 to 20 mill ##ili ##ters of water . pot 2 , 3 , and 4 had been watered between 10 and 20 mill ##ili ##ters of water and they were the only ones that grew . [SEP]
11/11/2020 13:40:06 - INFO - __main__ -  553 -   input_ids: 101 2184 4971 18622 7747 2000 2322 4971 18622 7747 1012 1996 10958 10521 15689 2106 2025 4982 2012 2035 1999 18911 2028 1998 1019 2061 1996 2846 1997 13986 2003 2005 18911 1016 1010 1017 1998 1018 1010 2029 2288 2184 2000 2322 4971 18622 7747 1997 2300 1012 102 2184 2000 2322 4971 18622 7747 1997 2300 1012 8962 1016 1010 1017 1010 1998 1018 2018 2042 27129 2090 2184 1998 2322 4971 18622 7747 1997 2300 1998 2027 2020 1996 2069 3924 2008 3473 1012 102 0
11/11/2020 13:40:06 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
11/11/2020 13:40:06 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0
11/11/2020 13:40:06 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 13:40:06 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 13:40:06 - INFO - __main__ -  550 -   guid: dev-3
11/11/2020 13:40:06 - INFO - __main__ -  552 -   tokens: [CLS] 10 mill ##ili ##ters to 20 mill ##ili ##ters . the ra ##dis ##hes did not grow at all in pots one and 5 so the range of tolerance is for pots 2 , 3 and 4 , which got 10 to 20 mill ##ili ##ters of water . [SEP] 10 to 20 mill ##ili ##ters water , i looked at which plant roots grew . [SEP]
11/11/2020 13:40:06 - INFO - __main__ -  553 -   input_ids: 101 2184 4971 18622 7747 2000 2322 4971 18622 7747 1012 1996 10958 10521 15689 2106 2025 4982 2012 2035 1999 18911 2028 1998 1019 2061 1996 2846 1997 13986 2003 2005 18911 1016 1010 1017 1998 1018 1010 2029 2288 2184 2000 2322 4971 18622 7747 1997 2300 1012 102 2184 2000 2322 4971 18622 7747 2300 1010 1045 2246 2012 2029 3269 6147 3473 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 13:40:06 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 13:40:06 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 13:40:06 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 13:40:06 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 13:40:06 - INFO - __main__ -  550 -   guid: dev-4
11/11/2020 13:40:06 - INFO - __main__ -  552 -   tokens: [CLS] 10 mill ##ili ##ters to 20 mill ##ili ##ters . the ra ##dis ##hes did not grow at all in pots one and 5 so the range of tolerance is for pots 2 , 3 and 4 , which got 10 to 20 mill ##ili ##ters of water . [SEP] 10 to 20 mill ##ili ##ters of water , none grew in one or 5 so those do not count for range of tolerance . [SEP]
11/11/2020 13:40:06 - INFO - __main__ -  553 -   input_ids: 101 2184 4971 18622 7747 2000 2322 4971 18622 7747 1012 1996 10958 10521 15689 2106 2025 4982 2012 2035 1999 18911 2028 1998 1019 2061 1996 2846 1997 13986 2003 2005 18911 1016 1010 1017 1998 1018 1010 2029 2288 2184 2000 2322 4971 18622 7747 1997 2300 1012 102 2184 2000 2322 4971 18622 7747 1997 2300 1010 3904 3473 1999 2028 2030 1019 2061 2216 2079 2025 4175 2005 2846 1997 13986 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 13:40:06 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 13:40:06 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 13:40:06 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 13:40:06 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 13:40:06 - INFO - __main__ -  550 -   guid: dev-5
11/11/2020 13:40:06 - INFO - __main__ -  552 -   tokens: [CLS] 10 mill ##ili ##ters to 20 mill ##ili ##ters . the ra ##dis ##hes did not grow at all in pots one and 5 so the range of tolerance is for pots 2 , 3 and 4 , which got 10 to 20 mill ##ili ##ters of water . [SEP] 10 to 20 mill ##ili ##ters , well in pot one nothing grew same in pot 5 so the one that grew are a range of tolerance form 10 mill ##ili ##ters to 20 mill ##ili ##ters . [SEP]
11/11/2020 13:40:06 - INFO - __main__ -  553 -   input_ids: 101 2184 4971 18622 7747 2000 2322 4971 18622 7747 1012 1996 10958 10521 15689 2106 2025 4982 2012 2035 1999 18911 2028 1998 1019 2061 1996 2846 1997 13986 2003 2005 18911 1016 1010 1017 1998 1018 1010 2029 2288 2184 2000 2322 4971 18622 7747 1997 2300 1012 102 2184 2000 2322 4971 18622 7747 1010 2092 1999 8962 2028 2498 3473 2168 1999 8962 1019 2061 1996 2028 2008 3473 2024 1037 2846 1997 13986 2433 2184 4971 18622 7747 2000 2322 4971 18622 7747 1012 102
11/11/2020 13:40:06 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
11/11/2020 13:40:06 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
11/11/2020 13:40:06 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 13:40:08 - INFO - __main__ -  1078 -   ***** Running evaluation *****
11/11/2020 13:40:08 - INFO - __main__ -  1079 -     Num examples = 4562
11/11/2020 13:40:08 - INFO - __main__ -  1080 -     Batch size = 8
11/11/2020 13:52:34 - INFO - __main__ -  1160 -   ***** Eval results *****
11/11/2020 13:52:34 - INFO - __main__ -  1162 -     acc = {'acc': 0.6900482244629549, 'm_f1': 0.6859042789917336, 'w_f1': 0.691661516211293}
11/11/2020 13:52:34 - INFO - __main__ -  1162 -     eval_loss = 0.9986225637899232
11/11/2020 13:52:34 - INFO - __main__ -  1162 -     global_step = 933
11/11/2020 13:52:34 - INFO - __main__ -  1162 -     loss = 0.04213793358355281
11/11/2020 14:09:34 - INFO - __main__ -  832 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/11/2020 14:09:35 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/11/2020 14:09:35 - INFO - __main__ -  174 -   LOOKING AT F:\PYTHONproject\the-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/11/2020 14:09:35 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 14:09:35 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/11/2020 14:09:35 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 14:09:35 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/11/2020 14:09:35 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 14:09:35 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/11/2020 14:09:35 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 14:09:35 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/11/2020 14:09:35 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 14:09:35 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/11/2020 14:09:35 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/11/2020 14:09:35 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpwgk3iwpf
11/11/2020 14:09:39 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/11/2020 14:09:42 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/11/2020 14:09:42 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/11/2020 14:09:42 - INFO - __main__ -  483 -   Writing example 0 of 4969
11/11/2020 14:09:42 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 14:09:42 - INFO - __main__ -  550 -   guid: train-1
11/11/2020 14:09:42 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/11/2020 14:09:42 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 14:09:42 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 14:09:42 - INFO - __main__ -  550 -   guid: train-2
11/11/2020 14:09:42 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/11/2020 14:09:42 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 14:09:42 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 14:09:42 - INFO - __main__ -  550 -   guid: train-3
11/11/2020 14:09:42 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/11/2020 14:09:42 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 14:09:42 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 14:09:42 - INFO - __main__ -  550 -   guid: train-4
11/11/2020 14:09:42 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/11/2020 14:09:42 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 14:09:42 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 14:09:42 - INFO - __main__ -  550 -   guid: train-5
11/11/2020 14:09:42 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/11/2020 14:09:42 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:09:42 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 14:09:45 - INFO - __main__ -  938 -   ***** Running training *****
11/11/2020 14:09:45 - INFO - __main__ -  939 -     Num examples = 4969
11/11/2020 14:09:45 - INFO - __main__ -  940 -     Batch size = 16
11/11/2020 14:09:45 - INFO - __main__ -  941 -     Num steps = 930
11/11/2020 14:10:34 - INFO - __main__ -  832 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/11/2020 14:10:34 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/11/2020 14:10:34 - INFO - __main__ -  174 -   LOOKING AT F:\PYTHONproject\the-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/11/2020 14:10:34 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 14:10:34 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/11/2020 14:10:34 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 14:10:34 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/11/2020 14:10:34 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 14:10:34 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/11/2020 14:10:34 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 14:10:34 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/11/2020 14:10:34 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 14:10:34 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/11/2020 14:10:34 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/11/2020 14:10:34 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpqjmpsv40
11/11/2020 14:10:38 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/11/2020 14:10:41 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/11/2020 14:10:41 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/11/2020 14:10:41 - INFO - __main__ -  483 -   Writing example 0 of 4969
11/11/2020 14:10:41 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 14:10:41 - INFO - __main__ -  550 -   guid: train-1
11/11/2020 14:10:41 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/11/2020 14:10:41 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 14:10:41 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 14:10:41 - INFO - __main__ -  550 -   guid: train-2
11/11/2020 14:10:41 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/11/2020 14:10:41 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 14:10:41 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 14:10:41 - INFO - __main__ -  550 -   guid: train-3
11/11/2020 14:10:41 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/11/2020 14:10:41 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 14:10:41 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 14:10:41 - INFO - __main__ -  550 -   guid: train-4
11/11/2020 14:10:41 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/11/2020 14:10:41 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 14:10:41 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 14:10:41 - INFO - __main__ -  550 -   guid: train-5
11/11/2020 14:10:41 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/11/2020 14:10:41 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 14:10:41 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 14:10:44 - INFO - __main__ -  938 -   ***** Running training *****
11/11/2020 14:10:44 - INFO - __main__ -  939 -     Num examples = 4969
11/11/2020 14:10:44 - INFO - __main__ -  940 -     Batch size = 16
11/11/2020 14:10:44 - INFO - __main__ -  941 -     Num steps = 930
11/11/2020 16:38:24 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/11/2020 16:38:31 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/11/2020 16:38:37 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/11/2020 16:38:37 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/11/2020 16:38:40 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/11/2020 16:38:40 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:38:40 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/11/2020 16:38:40 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:38:40 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/11/2020 16:38:40 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:38:40 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/11/2020 16:38:40 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:38:40 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/11/2020 16:38:40 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:38:40 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/11/2020 16:38:40 - INFO - __main__ -  483 -   Writing example 0 of 540
11/11/2020 16:38:40 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:38:40 - INFO - __main__ -  550 -   guid: dev-1
11/11/2020 16:38:40 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/11/2020 16:38:40 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 16:38:40 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:38:40 - INFO - __main__ -  550 -   guid: dev-2
11/11/2020 16:38:40 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/11/2020 16:38:40 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 16:38:40 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:38:40 - INFO - __main__ -  550 -   guid: dev-3
11/11/2020 16:38:40 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/11/2020 16:38:40 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 16:38:40 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:38:40 - INFO - __main__ -  550 -   guid: dev-4
11/11/2020 16:38:40 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/11/2020 16:38:40 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 16:38:40 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:38:40 - INFO - __main__ -  550 -   guid: dev-5
11/11/2020 16:38:40 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/11/2020 16:38:40 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:38:40 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 16:38:41 - INFO - __main__ -  1078 -   ***** Running evaluation *****
11/11/2020 16:38:41 - INFO - __main__ -  1079 -     Num examples = 540
11/11/2020 16:38:41 - INFO - __main__ -  1080 -     Batch size = 8
11/11/2020 16:40:09 - INFO - __main__ -  1160 -   ***** Eval results *****
11/11/2020 16:40:09 - INFO - __main__ -  1162 -     acc = {'acc': 0.812962962962963, 'm_f1': 0.8067266496805355, 'w_f1': 0.8114842495042431}
11/11/2020 16:40:09 - INFO - __main__ -  1162 -     eval_loss = 0.6148143179906422
11/11/2020 16:40:09 - INFO - __main__ -  1162 -     global_step = 933
11/11/2020 16:40:09 - INFO - __main__ -  1162 -     loss = 0.04213793358355281
11/11/2020 16:54:33 - INFO - __main__ -  832 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/11/2020 16:54:42 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/11/2020 16:54:42 - INFO - __main__ -  174 -   LOOKING AT F:\PYTHONproject\the-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/11/2020 16:54:42 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:54:42 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/11/2020 16:54:42 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:54:42 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/11/2020 16:54:42 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:54:42 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/11/2020 16:54:42 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:54:42 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/11/2020 16:54:42 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:54:42 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/11/2020 16:54:46 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/11/2020 16:54:46 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmp39khr94f
11/11/2020 16:54:52 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/11/2020 16:54:54 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/11/2020 16:54:54 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/11/2020 16:54:54 - INFO - __main__ -  483 -   Writing example 0 of 4969
11/11/2020 16:54:54 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:54:54 - INFO - __main__ -  550 -   guid: train-1
11/11/2020 16:54:54 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/11/2020 16:54:54 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 16:54:54 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:54:54 - INFO - __main__ -  550 -   guid: train-2
11/11/2020 16:54:54 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/11/2020 16:54:54 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 16:54:54 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:54:54 - INFO - __main__ -  550 -   guid: train-3
11/11/2020 16:54:54 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/11/2020 16:54:54 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 16:54:54 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:54:54 - INFO - __main__ -  550 -   guid: train-4
11/11/2020 16:54:54 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/11/2020 16:54:54 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 16:54:54 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:54:54 - INFO - __main__ -  550 -   guid: train-5
11/11/2020 16:54:54 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/11/2020 16:54:54 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:54:54 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 16:54:57 - INFO - __main__ -  938 -   ***** Running training *****
11/11/2020 16:54:57 - INFO - __main__ -  939 -     Num examples = 4969
11/11/2020 16:54:57 - INFO - __main__ -  940 -     Batch size = 16
11/11/2020 16:54:57 - INFO - __main__ -  941 -     Num steps = 930
11/11/2020 16:55:30 - INFO - __main__ -  832 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/11/2020 16:55:32 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/11/2020 16:55:32 - INFO - __main__ -  174 -   LOOKING AT F:\PYTHONproject\the-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/11/2020 16:55:32 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:55:32 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/11/2020 16:55:32 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:55:32 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/11/2020 16:55:32 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:55:32 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/11/2020 16:55:32 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:55:32 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/11/2020 16:55:32 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 16:55:32 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/11/2020 16:55:33 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/11/2020 16:55:33 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmp49abvw4v
11/11/2020 16:55:38 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/11/2020 16:55:40 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/11/2020 16:55:40 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/11/2020 16:55:40 - INFO - __main__ -  483 -   Writing example 0 of 4969
11/11/2020 16:55:40 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:55:40 - INFO - __main__ -  550 -   guid: train-1
11/11/2020 16:55:40 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/11/2020 16:55:40 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 16:55:40 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:55:40 - INFO - __main__ -  550 -   guid: train-2
11/11/2020 16:55:40 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/11/2020 16:55:40 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 16:55:40 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:55:40 - INFO - __main__ -  550 -   guid: train-3
11/11/2020 16:55:40 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/11/2020 16:55:40 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 16:55:40 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:55:40 - INFO - __main__ -  550 -   guid: train-4
11/11/2020 16:55:40 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/11/2020 16:55:40 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 16:55:40 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 16:55:40 - INFO - __main__ -  550 -   guid: train-5
11/11/2020 16:55:40 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/11/2020 16:55:40 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 16:55:40 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 16:55:42 - INFO - __main__ -  938 -   ***** Running training *****
11/11/2020 16:55:42 - INFO - __main__ -  939 -     Num examples = 4969
11/11/2020 16:55:42 - INFO - __main__ -  940 -     Batch size = 16
11/11/2020 16:55:42 - INFO - __main__ -  941 -     Num steps = 930
11/11/2020 19:21:11 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/11/2020 19:21:17 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/11/2020 19:21:20 - INFO - pytorch_pretrained_bert.modeling -  580 -   loading archive file output
11/11/2020 19:21:20 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/11/2020 19:21:22 - INFO - pytorch_pretrained_bert.tokenization -  187 -   loading vocabulary file output\vocab.txt
11/11/2020 19:21:22 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 19:21:22 - INFO - __main__ -  199 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I know the paperclip would scratch it because a paperclip is harder than a penny.] label: [correct]
11/11/2020 19:21:22 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 19:21:22 - INFO - __main__ -  199 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I knew that because the paperclip is harder than the penny.] label: [correct]
11/11/2020 19:21:22 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 19:21:22 - INFO - __main__ -  199 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I know that the paperclip would scratch the mineral because a paperclip is harder than a penny.] label: [correct]
11/11/2020 19:21:22 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 19:21:22 - INFO - __main__ -  199 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [Because the paperclip is an easier item to scratch a rock or mineral than a penny.] label: [incorrect]
11/11/2020 19:21:22 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/11/2020 19:21:22 - INFO - __main__ -  199 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I know that a paperclip will scratch it because it is the hardest tool that we used out of a fingernail, penny and paperclip.] label: [correct]
11/11/2020 19:21:22 - INFO - __main__ -  483 -   Writing example 0 of 733
11/11/2020 19:21:22 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 19:21:22 - INFO - __main__ -  550 -   guid: dev-1
11/11/2020 19:21:22 - INFO - __main__ -  552 -   tokens: [CLS] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i know the paper ##cl ##ip would scratch it because a paper ##cl ##ip is harder than a penny . [SEP]
11/11/2020 19:21:22 - INFO - __main__ -  553 -   input_ids: 101 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2113 1996 3259 20464 11514 2052 11969 2009 2138 1037 3259 20464 11514 2003 6211 2084 1037 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 19:21:22 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 19:21:22 - INFO - __main__ -  550 -   guid: dev-2
11/11/2020 19:21:22 - INFO - __main__ -  552 -   tokens: [CLS] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i knew that because the paper ##cl ##ip is harder than the penny . [SEP]
11/11/2020 19:21:22 - INFO - __main__ -  553 -   input_ids: 101 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2354 2008 2138 1996 3259 20464 11514 2003 6211 2084 1996 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 19:21:22 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 19:21:22 - INFO - __main__ -  550 -   guid: dev-3
11/11/2020 19:21:22 - INFO - __main__ -  552 -   tokens: [CLS] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i know that the paper ##cl ##ip would scratch the mineral because a paper ##cl ##ip is harder than a penny . [SEP]
11/11/2020 19:21:22 - INFO - __main__ -  553 -   input_ids: 101 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2113 2008 1996 3259 20464 11514 2052 11969 1996 9754 2138 1037 3259 20464 11514 2003 6211 2084 1037 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 19:21:22 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 19:21:22 - INFO - __main__ -  550 -   guid: dev-4
11/11/2020 19:21:22 - INFO - __main__ -  552 -   tokens: [CLS] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] because the paper ##cl ##ip is an easier item to scratch a rock or mineral than a penny . [SEP]
11/11/2020 19:21:22 - INFO - __main__ -  553 -   input_ids: 101 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 2138 1996 3259 20464 11514 2003 2019 6082 8875 2000 11969 1037 2600 2030 9754 2084 1037 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/11/2020 19:21:22 - INFO - __main__ -  549 -   *** Example ***
11/11/2020 19:21:22 - INFO - __main__ -  550 -   guid: dev-5
11/11/2020 19:21:22 - INFO - __main__ -  552 -   tokens: [CLS] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i know that a paper ##cl ##ip will scratch it because it is the hardest tool that we used out of a finger ##nail , penny and paper ##cl ##ip . [SEP]
11/11/2020 19:21:22 - INFO - __main__ -  553 -   input_ids: 101 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2113 2008 1037 3259 20464 11514 2097 11969 2009 2138 2009 2003 1996 18263 6994 2008 2057 2109 2041 1997 1037 4344 25464 1010 10647 1998 3259 20464 11514 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/11/2020 19:21:22 - INFO - __main__ -  557 -   label: correct (id = 0)
11/11/2020 19:21:22 - INFO - __main__ -  1078 -   ***** Running evaluation *****
11/11/2020 19:21:22 - INFO - __main__ -  1079 -     Num examples = 733
11/11/2020 19:21:22 - INFO - __main__ -  1080 -     Batch size = 8
11/11/2020 19:23:18 - INFO - __main__ -  1160 -   ***** Eval results *****
11/11/2020 19:23:18 - INFO - __main__ -  1162 -     acc = {'acc': 0.713506139154161, 'm_f1': 0.708399636280973, 'w_f1': 0.7152960473777527}
11/11/2020 19:23:18 - INFO - __main__ -  1162 -     eval_loss = 0.9129427224600121
11/11/2020 19:23:18 - INFO - __main__ -  1162 -     global_step = 933
11/11/2020 19:23:18 - INFO - __main__ -  1162 -     loss = 0.04213793358355281
11/14/2020 15:16:26 - INFO - __main__ -  832 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/14/2020 15:16:26 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/14/2020 15:16:26 - INFO - __main__ -  174 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/14/2020 15:16:26 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 15:16:26 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/14/2020 15:16:26 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 15:16:26 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/14/2020 15:16:26 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 15:16:26 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/14/2020 15:16:26 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 15:16:26 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/14/2020 15:16:26 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 15:16:26 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/14/2020 15:16:26 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/14/2020 15:16:26 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmp2yiqesmm
11/14/2020 15:16:37 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/14/2020 15:16:42 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/14/2020 15:16:42 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/14/2020 15:16:42 - INFO - __main__ -  483 -   Writing example 0 of 4969
11/14/2020 15:16:42 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 15:16:42 - INFO - __main__ -  550 -   guid: train-1
11/14/2020 15:16:42 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/14/2020 15:16:42 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/14/2020 15:16:42 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 15:16:42 - INFO - __main__ -  550 -   guid: train-2
11/14/2020 15:16:42 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/14/2020 15:16:42 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  557 -   label: correct (id = 0)
11/14/2020 15:16:42 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 15:16:42 - INFO - __main__ -  550 -   guid: train-3
11/14/2020 15:16:42 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/14/2020 15:16:42 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  557 -   label: correct (id = 0)
11/14/2020 15:16:42 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 15:16:42 - INFO - __main__ -  550 -   guid: train-4
11/14/2020 15:16:42 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/14/2020 15:16:42 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/14/2020 15:16:42 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 15:16:42 - INFO - __main__ -  550 -   guid: train-5
11/14/2020 15:16:42 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/14/2020 15:16:42 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:42 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/14/2020 15:16:45 - INFO - __main__ -  938 -   ***** Running training *****
11/14/2020 15:16:45 - INFO - __main__ -  939 -     Num examples = 4969
11/14/2020 15:16:45 - INFO - __main__ -  940 -     Batch size = 16
11/14/2020 15:16:45 - INFO - __main__ -  941 -     Num steps = 930
11/14/2020 15:16:45 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 15:16:45 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We evaporated the water.] label: [correct]
11/14/2020 15:16:45 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 15:16:45 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We poured just the water into another thing and let the water evaporate.] label: [correct]
11/14/2020 15:16:45 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 15:16:45 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [We kept the salt in the vial and put the water in the Petri dish.] label: [incorrect]
11/14/2020 15:16:45 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 15:16:45 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Get all the water out.] label: [incorrect]
11/14/2020 15:16:45 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 15:16:45 - INFO - __main__ -  199 -   text_a: [The crystals were square with Xs on the surface.] test_b: [Well because we broke them apart.] label: [incorrect]
11/14/2020 15:16:45 - INFO - __main__ -  483 -   Writing example 0 of 540
11/14/2020 15:16:45 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 15:16:45 - INFO - __main__ -  550 -   guid: dev-1
11/14/2020 15:16:45 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we eva ##por ##ated the water . [SEP]
11/14/2020 15:16:45 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 9345 17822 4383 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  557 -   label: correct (id = 0)
11/14/2020 15:16:45 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 15:16:45 - INFO - __main__ -  550 -   guid: dev-2
11/14/2020 15:16:45 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we poured just the water into another thing and let the water eva ##por ##ate . [SEP]
11/14/2020 15:16:45 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 8542 2074 1996 2300 2046 2178 2518 1998 2292 1996 2300 9345 17822 3686 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  557 -   label: correct (id = 0)
11/14/2020 15:16:45 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 15:16:45 - INFO - __main__ -  550 -   guid: dev-3
11/14/2020 15:16:45 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] we kept the salt in the vial and put the water in the pet ##ri dish . [SEP]
11/14/2020 15:16:45 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2057 2921 1996 5474 1999 1996 28475 1998 2404 1996 2300 1999 1996 9004 3089 9841 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/14/2020 15:16:45 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 15:16:45 - INFO - __main__ -  550 -   guid: dev-4
11/14/2020 15:16:45 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] get all the water out . [SEP]
11/14/2020 15:16:45 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2131 2035 1996 2300 2041 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/14/2020 15:16:45 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 15:16:45 - INFO - __main__ -  550 -   guid: dev-5
11/14/2020 15:16:45 - INFO - __main__ -  552 -   tokens: [CLS] the crystals were square with x ##s on the surface . [SEP] well because we broke them apart . [SEP]
11/14/2020 15:16:45 - INFO - __main__ -  553 -   input_ids: 101 1996 14438 2020 2675 2007 1060 2015 2006 1996 3302 1012 102 2092 2138 2057 3631 2068 4237 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 15:16:45 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/14/2020 15:16:45 - INFO - __main__ -  970 -   ***** Running evaluation *****
11/14/2020 15:16:45 - INFO - __main__ -  971 -     Num examples = 540
11/14/2020 15:16:45 - INFO - __main__ -  972 -     Batch size = 8
11/14/2020 17:36:02 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/14/2020 17:36:07 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/14/2020 18:18:45 - INFO - __main__ -  832 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/14/2020 18:18:46 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/14/2020 18:18:46 - INFO - __main__ -  174 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/14/2020 18:18:46 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 18:18:46 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/14/2020 18:18:46 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 18:18:46 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/14/2020 18:18:46 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 18:18:46 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/14/2020 18:18:46 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 18:18:46 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/14/2020 18:18:46 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 18:18:46 - INFO - __main__ -  199 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/14/2020 18:18:48 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/14/2020 18:18:48 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpecf15ao_
11/14/2020 18:18:55 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/14/2020 18:18:58 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/14/2020 18:18:58 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/14/2020 18:18:58 - INFO - __main__ -  483 -   Writing example 0 of 4969
11/14/2020 18:18:58 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 18:18:58 - INFO - __main__ -  550 -   guid: train-1
11/14/2020 18:18:58 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/14/2020 18:18:58 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/14/2020 18:18:58 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 18:18:58 - INFO - __main__ -  550 -   guid: train-2
11/14/2020 18:18:58 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/14/2020 18:18:58 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  557 -   label: correct (id = 0)
11/14/2020 18:18:58 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 18:18:58 - INFO - __main__ -  550 -   guid: train-3
11/14/2020 18:18:58 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/14/2020 18:18:58 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  557 -   label: correct (id = 0)
11/14/2020 18:18:58 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 18:18:58 - INFO - __main__ -  550 -   guid: train-4
11/14/2020 18:18:58 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/14/2020 18:18:58 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/14/2020 18:18:58 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 18:18:58 - INFO - __main__ -  550 -   guid: train-5
11/14/2020 18:18:58 - INFO - __main__ -  552 -   tokens: [CLS] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/14/2020 18:18:58 - INFO - __main__ -  553 -   input_ids: 101 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:18:58 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/14/2020 18:19:00 - INFO - __main__ -  938 -   ***** Running training *****
11/14/2020 18:19:00 - INFO - __main__ -  939 -     Num examples = 4969
11/14/2020 18:19:00 - INFO - __main__ -  940 -     Batch size = 16
11/14/2020 18:19:00 - INFO - __main__ -  941 -     Num steps = 3100
11/14/2020 18:19:00 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 18:19:00 - INFO - __main__ -  199 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I know the paperclip would scratch it because a paperclip is harder than a penny.] label: [correct]
11/14/2020 18:19:00 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 18:19:00 - INFO - __main__ -  199 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I knew that because the paperclip is harder than the penny.] label: [correct]
11/14/2020 18:19:00 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 18:19:00 - INFO - __main__ -  199 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I know that the paperclip would scratch the mineral because a paperclip is harder than a penny.] label: [correct]
11/14/2020 18:19:00 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 18:19:00 - INFO - __main__ -  199 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [Because the paperclip is an easier item to scratch a rock or mineral than a penny.] label: [incorrect]
11/14/2020 18:19:00 - INFO - __main__ -  198 -   **** 2way samples of sciencesbank ****
11/14/2020 18:19:00 - INFO - __main__ -  199 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I know that a paperclip will scratch it because it is the hardest tool that we used out of a fingernail, penny and paperclip.] label: [correct]
11/14/2020 18:19:00 - INFO - __main__ -  483 -   Writing example 0 of 733
11/14/2020 18:19:00 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 18:19:00 - INFO - __main__ -  550 -   guid: dev-1
11/14/2020 18:19:00 - INFO - __main__ -  552 -   tokens: [CLS] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i know the paper ##cl ##ip would scratch it because a paper ##cl ##ip is harder than a penny . [SEP]
11/14/2020 18:19:00 - INFO - __main__ -  553 -   input_ids: 101 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2113 1996 3259 20464 11514 2052 11969 2009 2138 1037 3259 20464 11514 2003 6211 2084 1037 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  557 -   label: correct (id = 0)
11/14/2020 18:19:00 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 18:19:00 - INFO - __main__ -  550 -   guid: dev-2
11/14/2020 18:19:00 - INFO - __main__ -  552 -   tokens: [CLS] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i knew that because the paper ##cl ##ip is harder than the penny . [SEP]
11/14/2020 18:19:00 - INFO - __main__ -  553 -   input_ids: 101 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2354 2008 2138 1996 3259 20464 11514 2003 6211 2084 1996 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  557 -   label: correct (id = 0)
11/14/2020 18:19:00 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 18:19:00 - INFO - __main__ -  550 -   guid: dev-3
11/14/2020 18:19:00 - INFO - __main__ -  552 -   tokens: [CLS] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i know that the paper ##cl ##ip would scratch the mineral because a paper ##cl ##ip is harder than a penny . [SEP]
11/14/2020 18:19:00 - INFO - __main__ -  553 -   input_ids: 101 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2113 2008 1996 3259 20464 11514 2052 11969 1996 9754 2138 1037 3259 20464 11514 2003 6211 2084 1037 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  557 -   label: correct (id = 0)
11/14/2020 18:19:00 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 18:19:00 - INFO - __main__ -  550 -   guid: dev-4
11/14/2020 18:19:00 - INFO - __main__ -  552 -   tokens: [CLS] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] because the paper ##cl ##ip is an easier item to scratch a rock or mineral than a penny . [SEP]
11/14/2020 18:19:00 - INFO - __main__ -  553 -   input_ids: 101 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 2138 1996 3259 20464 11514 2003 2019 6082 8875 2000 11969 1037 2600 2030 9754 2084 1037 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  557 -   label: incorrect (id = 1)
11/14/2020 18:19:00 - INFO - __main__ -  549 -   *** Example ***
11/14/2020 18:19:00 - INFO - __main__ -  550 -   guid: dev-5
11/14/2020 18:19:00 - INFO - __main__ -  552 -   tokens: [CLS] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i know that a paper ##cl ##ip will scratch it because it is the hardest tool that we used out of a finger ##nail , penny and paper ##cl ##ip . [SEP]
11/14/2020 18:19:00 - INFO - __main__ -  553 -   input_ids: 101 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2113 2008 1037 3259 20464 11514 2097 11969 2009 2138 2009 2003 1996 18263 6994 2008 2057 2109 2041 1997 1037 4344 25464 1010 10647 1998 3259 20464 11514 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  554 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  556 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/14/2020 18:19:00 - INFO - __main__ -  557 -   label: correct (id = 0)
11/14/2020 18:19:00 - INFO - __main__ -  970 -   ***** Running evaluation *****
11/14/2020 18:19:00 - INFO - __main__ -  971 -     Num examples = 733
11/14/2020 18:19:00 - INFO - __main__ -  972 -     Batch size = 8
11/15/2020 01:38:29 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/15/2020 01:38:37 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/15/2020 01:38:45 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/15/2020 01:38:53 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/15/2020 01:39:01 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/15/2020 01:39:10 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/15/2020 01:39:18 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/15/2020 01:39:26 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/15/2020 01:39:31 - WARNING - pytorch_pretrained_bert.optimization -  67 -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.
11/17/2020 17:26:56 - INFO - __main__ -  835 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/17/2020 17:26:58 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/17/2020 17:26:58 - INFO - __main__ -  174 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/17/2020 17:26:58 - INFO - __main__ -  202 -   **** 2way samples of sciencesbank ****
11/17/2020 17:26:58 - INFO - __main__ -  203 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/17/2020 17:28:23 - INFO - __main__ -  836 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/17/2020 17:28:24 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/17/2020 17:28:24 - INFO - __main__ -  175 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/17/2020 17:28:24 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 17:28:24 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/17/2020 17:28:24 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 17:28:24 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/17/2020 17:28:24 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 17:28:24 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/17/2020 17:28:24 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 17:28:24 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/17/2020 17:28:24 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 17:28:24 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/17/2020 17:28:34 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/17/2020 17:28:34 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmptb4e9_wb
11/17/2020 17:28:39 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/17/2020 17:28:42 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/17/2020 17:28:42 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/17/2020 17:28:42 - INFO - __main__ -  488 -   Writing example 0 of 4969
11/17/2020 17:28:42 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 17:28:42 - INFO - __main__ -  554 -   guid: train-1
11/17/2020 17:28:42 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/17/2020 17:28:42 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 17:28:42 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 17:28:42 - INFO - __main__ -  554 -   guid: train-2
11/17/2020 17:28:42 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/17/2020 17:28:42 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 17:28:42 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 17:28:42 - INFO - __main__ -  554 -   guid: train-3
11/17/2020 17:28:42 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/17/2020 17:28:42 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 17:28:42 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 17:28:42 - INFO - __main__ -  554 -   guid: train-4
11/17/2020 17:28:42 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/17/2020 17:28:42 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 17:28:42 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 17:28:42 - INFO - __main__ -  554 -   guid: train-5
11/17/2020 17:28:42 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/17/2020 17:28:42 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 17:28:42 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:23:09 - INFO - __main__ -  836 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/17/2020 18:23:10 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/17/2020 18:23:10 - INFO - __main__ -  175 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/17/2020 18:23:10 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:23:10 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/17/2020 18:23:10 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:23:10 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/17/2020 18:23:10 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:23:10 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/17/2020 18:23:10 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:23:10 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/17/2020 18:23:10 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:23:10 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/17/2020 18:23:11 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/17/2020 18:23:11 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmplnsl7ekc
11/17/2020 18:23:16 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/17/2020 18:23:18 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/17/2020 18:23:18 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/17/2020 18:23:18 - INFO - __main__ -  488 -   Writing example 0 of 4969
11/17/2020 18:23:18 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:23:18 - INFO - __main__ -  554 -   guid: train-1
11/17/2020 18:23:18 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/17/2020 18:23:18 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:23:18 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:23:18 - INFO - __main__ -  554 -   guid: train-2
11/17/2020 18:23:18 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/17/2020 18:23:18 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:23:18 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:23:18 - INFO - __main__ -  554 -   guid: train-3
11/17/2020 18:23:18 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/17/2020 18:23:18 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:23:18 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:23:18 - INFO - __main__ -  554 -   guid: train-4
11/17/2020 18:23:18 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/17/2020 18:23:18 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:23:18 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:23:18 - INFO - __main__ -  554 -   guid: train-5
11/17/2020 18:23:18 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/17/2020 18:23:18 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:23:18 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:24:23 - INFO - __main__ -  836 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/17/2020 18:24:24 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/17/2020 18:24:25 - INFO - __main__ -  175 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/17/2020 18:24:25 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:24:25 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/17/2020 18:24:25 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:24:25 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/17/2020 18:24:25 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:24:25 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/17/2020 18:24:25 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:24:25 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/17/2020 18:24:25 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:24:25 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/17/2020 18:24:26 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/17/2020 18:24:26 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpku5egejo
11/17/2020 18:24:30 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/17/2020 18:24:32 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/17/2020 18:24:32 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/17/2020 18:24:32 - INFO - __main__ -  488 -   Writing example 0 of 4969
11/17/2020 18:24:32 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:24:32 - INFO - __main__ -  554 -   guid: train-1
11/17/2020 18:24:32 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/17/2020 18:24:32 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:24:32 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:24:32 - INFO - __main__ -  554 -   guid: train-2
11/17/2020 18:24:32 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/17/2020 18:24:32 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:24:32 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:24:32 - INFO - __main__ -  554 -   guid: train-3
11/17/2020 18:24:32 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/17/2020 18:24:32 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:24:32 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:24:32 - INFO - __main__ -  554 -   guid: train-4
11/17/2020 18:24:32 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/17/2020 18:24:32 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:24:32 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:24:32 - INFO - __main__ -  554 -   guid: train-5
11/17/2020 18:24:32 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/17/2020 18:24:32 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:24:32 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:25:30 - INFO - __main__ -  836 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/17/2020 18:25:51 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/17/2020 18:25:51 - INFO - __main__ -  175 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/17/2020 18:25:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:25:51 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/17/2020 18:25:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:25:51 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/17/2020 18:25:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:25:51 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/17/2020 18:25:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:25:51 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/17/2020 18:25:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:25:51 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/17/2020 18:25:52 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/17/2020 18:25:52 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpmyovkolm
11/17/2020 18:25:57 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/17/2020 18:25:59 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/17/2020 18:25:59 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/17/2020 18:25:59 - INFO - __main__ -  488 -   Writing example 0 of 4969
11/17/2020 18:25:59 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:25:59 - INFO - __main__ -  554 -   guid: train-1
11/17/2020 18:25:59 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/17/2020 18:25:59 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:25:59 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:25:59 - INFO - __main__ -  554 -   guid: train-2
11/17/2020 18:25:59 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/17/2020 18:25:59 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:25:59 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:25:59 - INFO - __main__ -  554 -   guid: train-3
11/17/2020 18:25:59 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/17/2020 18:25:59 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:25:59 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:25:59 - INFO - __main__ -  554 -   guid: train-4
11/17/2020 18:25:59 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/17/2020 18:25:59 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:25:59 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:25:59 - INFO - __main__ -  554 -   guid: train-5
11/17/2020 18:25:59 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/17/2020 18:25:59 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:25:59 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:28:01 - INFO - __main__ -  836 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/17/2020 18:28:02 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/17/2020 18:28:02 - INFO - __main__ -  175 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/17/2020 18:28:02 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:28:02 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/17/2020 18:28:02 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:28:02 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/17/2020 18:28:02 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:28:02 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/17/2020 18:28:02 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:28:02 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/17/2020 18:28:02 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:28:02 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/17/2020 18:28:03 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/17/2020 18:28:03 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmp9y9qvvnk
11/17/2020 18:28:07 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/17/2020 18:28:10 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/17/2020 18:28:10 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/17/2020 18:28:10 - INFO - __main__ -  488 -   Writing example 0 of 4969
11/17/2020 18:28:10 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:28:10 - INFO - __main__ -  554 -   guid: train-1
11/17/2020 18:28:10 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/17/2020 18:28:10 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:28:10 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:28:10 - INFO - __main__ -  554 -   guid: train-2
11/17/2020 18:28:10 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/17/2020 18:28:10 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:28:10 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:28:10 - INFO - __main__ -  554 -   guid: train-3
11/17/2020 18:28:10 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/17/2020 18:28:10 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:28:10 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:28:10 - INFO - __main__ -  554 -   guid: train-4
11/17/2020 18:28:10 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/17/2020 18:28:10 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:28:10 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:28:10 - INFO - __main__ -  554 -   guid: train-5
11/17/2020 18:28:10 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/17/2020 18:28:10 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:10 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:28:50 - INFO - __main__ -  836 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/17/2020 18:28:51 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/17/2020 18:28:51 - INFO - __main__ -  175 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/17/2020 18:28:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:28:51 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/17/2020 18:28:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:28:51 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/17/2020 18:28:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:28:51 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/17/2020 18:28:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:28:51 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/17/2020 18:28:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:28:51 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/17/2020 18:28:52 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/17/2020 18:28:52 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmp1x1j_41d
11/17/2020 18:28:57 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/17/2020 18:28:59 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/17/2020 18:28:59 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/17/2020 18:28:59 - INFO - __main__ -  488 -   Writing example 0 of 4969
11/17/2020 18:28:59 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:28:59 - INFO - __main__ -  554 -   guid: train-1
11/17/2020 18:28:59 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/17/2020 18:28:59 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:28:59 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:28:59 - INFO - __main__ -  554 -   guid: train-2
11/17/2020 18:28:59 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/17/2020 18:28:59 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:28:59 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:28:59 - INFO - __main__ -  554 -   guid: train-3
11/17/2020 18:28:59 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/17/2020 18:28:59 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:28:59 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:28:59 - INFO - __main__ -  554 -   guid: train-4
11/17/2020 18:28:59 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/17/2020 18:28:59 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:28:59 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:28:59 - INFO - __main__ -  554 -   guid: train-5
11/17/2020 18:28:59 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/17/2020 18:28:59 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:28:59 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:41:11 - INFO - __main__ -  838 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/17/2020 18:41:12 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/17/2020 18:41:12 - INFO - __main__ -  175 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/17/2020 18:41:12 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:41:12 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/17/2020 18:41:12 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:41:12 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/17/2020 18:41:12 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:41:12 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/17/2020 18:41:12 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:41:12 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/17/2020 18:41:12 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:41:12 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/17/2020 18:41:13 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/17/2020 18:41:13 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpsqtp89j3
11/17/2020 18:41:18 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/17/2020 18:41:21 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/17/2020 18:41:21 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/17/2020 18:41:21 - INFO - __main__ -  488 -   Writing example 0 of 4969
11/17/2020 18:45:01 - INFO - __main__ -  838 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/17/2020 18:45:05 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/17/2020 18:45:05 - INFO - __main__ -  175 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/17/2020 18:45:05 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:45:05 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/17/2020 18:45:05 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:45:05 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/17/2020 18:45:05 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:45:05 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/17/2020 18:45:05 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:45:05 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/17/2020 18:45:05 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:45:05 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/17/2020 18:45:10 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/17/2020 18:45:10 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpqz5q8ayw
11/17/2020 18:45:14 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/17/2020 18:45:17 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/17/2020 18:45:17 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/17/2020 18:45:17 - INFO - __main__ -  488 -   Writing example 0 of 4969
11/17/2020 18:45:17 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:45:17 - INFO - __main__ -  554 -   guid: train-1
11/17/2020 18:45:17 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/17/2020 18:45:17 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:45:17 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:45:17 - INFO - __main__ -  554 -   guid: train-2
11/17/2020 18:45:17 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/17/2020 18:45:17 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:45:17 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:45:17 - INFO - __main__ -  554 -   guid: train-3
11/17/2020 18:45:17 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/17/2020 18:45:17 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:45:17 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:45:17 - INFO - __main__ -  554 -   guid: train-4
11/17/2020 18:45:17 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/17/2020 18:45:17 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:45:17 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:45:17 - INFO - __main__ -  554 -   guid: train-5
11/17/2020 18:45:17 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/17/2020 18:45:17 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:45:17 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:46:10 - INFO - __main__ -  838 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/17/2020 18:46:13 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/17/2020 18:46:13 - INFO - __main__ -  175 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/17/2020 18:46:13 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:46:13 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/17/2020 18:46:13 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:46:13 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/17/2020 18:46:13 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:46:13 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/17/2020 18:46:13 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:46:13 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/17/2020 18:46:13 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:46:13 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/17/2020 18:46:15 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/17/2020 18:46:15 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpyyosuorb
11/17/2020 18:46:19 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/17/2020 18:46:21 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/17/2020 18:46:21 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/17/2020 18:46:21 - INFO - __main__ -  488 -   Writing example 0 of 4969
11/17/2020 18:46:21 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:46:21 - INFO - __main__ -  554 -   guid: train-1
11/17/2020 18:46:21 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/17/2020 18:46:21 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:46:21 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:46:21 - INFO - __main__ -  554 -   guid: train-2
11/17/2020 18:46:21 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/17/2020 18:46:21 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:46:21 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:46:21 - INFO - __main__ -  554 -   guid: train-3
11/17/2020 18:46:21 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/17/2020 18:46:21 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:46:21 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:46:21 - INFO - __main__ -  554 -   guid: train-4
11/17/2020 18:46:21 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/17/2020 18:46:21 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:46:21 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:46:21 - INFO - __main__ -  554 -   guid: train-5
11/17/2020 18:46:21 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/17/2020 18:46:21 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:46:21 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:48:22 - INFO - __main__ -  838 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/17/2020 18:48:23 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/17/2020 18:48:23 - INFO - __main__ -  175 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/17/2020 18:48:23 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:48:23 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/17/2020 18:48:23 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:48:23 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/17/2020 18:48:23 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:48:23 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/17/2020 18:48:23 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:48:23 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/17/2020 18:48:23 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:48:23 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/17/2020 18:48:24 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/17/2020 18:48:24 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpr94_9sw3
11/17/2020 18:48:28 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/17/2020 18:48:30 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/17/2020 18:48:30 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/17/2020 18:48:30 - INFO - __main__ -  488 -   Writing example 0 of 4969
11/17/2020 18:48:30 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:48:30 - INFO - __main__ -  554 -   guid: train-1
11/17/2020 18:48:30 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/17/2020 18:48:30 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:48:30 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:48:30 - INFO - __main__ -  554 -   guid: train-2
11/17/2020 18:48:30 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/17/2020 18:48:30 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:48:30 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:48:30 - INFO - __main__ -  554 -   guid: train-3
11/17/2020 18:48:30 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/17/2020 18:48:30 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:48:30 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:48:30 - INFO - __main__ -  554 -   guid: train-4
11/17/2020 18:48:30 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/17/2020 18:48:30 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:48:30 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:48:30 - INFO - __main__ -  554 -   guid: train-5
11/17/2020 18:48:30 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/17/2020 18:48:30 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:30 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:48:46 - INFO - __main__ -  838 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/17/2020 18:48:47 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/17/2020 18:48:47 - INFO - __main__ -  175 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/17/2020 18:48:47 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:48:47 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/17/2020 18:48:47 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:48:47 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/17/2020 18:48:47 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:48:47 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/17/2020 18:48:47 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:48:47 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/17/2020 18:48:47 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:48:47 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/17/2020 18:48:48 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/17/2020 18:48:48 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmpudigmmng
11/17/2020 18:48:53 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/17/2020 18:48:55 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/17/2020 18:48:55 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/17/2020 18:48:55 - INFO - __main__ -  488 -   Writing example 0 of 4969
11/17/2020 18:48:55 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:48:55 - INFO - __main__ -  554 -   guid: train-1
11/17/2020 18:48:55 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/17/2020 18:48:55 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:48:55 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:48:55 - INFO - __main__ -  554 -   guid: train-2
11/17/2020 18:48:55 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/17/2020 18:48:55 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:48:55 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:48:55 - INFO - __main__ -  554 -   guid: train-3
11/17/2020 18:48:55 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/17/2020 18:48:55 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:48:55 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:48:55 - INFO - __main__ -  554 -   guid: train-4
11/17/2020 18:48:55 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/17/2020 18:48:55 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:48:55 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:48:55 - INFO - __main__ -  554 -   guid: train-5
11/17/2020 18:48:55 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/17/2020 18:48:55 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:48:55 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:51:23 - INFO - __main__ -  838 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/17/2020 18:51:24 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/17/2020 18:51:24 - INFO - __main__ -  175 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/17/2020 18:51:24 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:51:24 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/17/2020 18:51:24 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:51:24 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/17/2020 18:51:24 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:51:24 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/17/2020 18:51:24 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:51:24 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/17/2020 18:51:24 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:51:24 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/17/2020 18:51:30 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/17/2020 18:51:30 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmptym95f2b
11/17/2020 18:51:34 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/17/2020 18:51:37 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/17/2020 18:51:37 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/17/2020 18:51:37 - INFO - __main__ -  488 -   Writing example 0 of 4969
11/17/2020 18:51:37 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:51:37 - INFO - __main__ -  554 -   guid: train-1
11/17/2020 18:51:37 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/17/2020 18:51:37 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:51:37 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:51:37 - INFO - __main__ -  554 -   guid: train-2
11/17/2020 18:51:37 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/17/2020 18:51:37 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:51:37 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:51:37 - INFO - __main__ -  554 -   guid: train-3
11/17/2020 18:51:37 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/17/2020 18:51:37 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:51:37 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:51:37 - INFO - __main__ -  554 -   guid: train-4
11/17/2020 18:51:37 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/17/2020 18:51:37 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:51:37 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:51:37 - INFO - __main__ -  554 -   guid: train-5
11/17/2020 18:51:37 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/17/2020 18:51:37 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:37 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:51:47 - INFO - __main__ -  944 -   ***** Running training *****
11/17/2020 18:51:47 - INFO - __main__ -  945 -     Num examples = 4969
11/17/2020 18:51:47 - INFO - __main__ -  946 -     Batch size = 16
11/17/2020 18:51:47 - INFO - __main__ -  947 -     Num steps = 930
11/17/2020 18:51:47 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:51:47 - INFO - __main__ -  204 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I know the paperclip would scratch it because a paperclip is harder than a penny.] label: [correct]
11/17/2020 18:51:47 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:51:47 - INFO - __main__ -  204 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I knew that because the paperclip is harder than the penny.] label: [correct]
11/17/2020 18:51:47 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:51:47 - INFO - __main__ -  204 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I know that the paperclip would scratch the mineral because a paperclip is harder than a penny.] label: [correct]
11/17/2020 18:51:47 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:51:47 - INFO - __main__ -  204 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [Because the paperclip is an easier item to scratch a rock or mineral than a penny.] label: [incorrect]
11/17/2020 18:51:47 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 18:51:47 - INFO - __main__ -  204 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I know that a paperclip will scratch it because it is the hardest tool that we used out of a fingernail, penny and paperclip.] label: [correct]
11/17/2020 18:51:47 - INFO - __main__ -  488 -   Writing example 0 of 733
11/17/2020 18:51:47 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:51:47 - INFO - __main__ -  554 -   guid: dev-1
11/17/2020 18:51:47 - INFO - __main__ -  556 -   tokens: [CLS] you used 3 scratch tools in class to test minerals for hardness : your finger ##nail , a penny , and a paper ##cl ##ip . if a mineral can be scratched by a penny , you can be sure that a ( paper ##cl ##ip ) will also scratch it . explain how you know that tool would scratch the mineral . [SEP] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i know the paper ##cl ##ip would scratch it because a paper ##cl ##ip is harder than a penny . [SEP]
11/17/2020 18:51:47 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 1017 11969 5906 1999 2465 2000 3231 13246 2005 23608 1024 2115 4344 25464 1010 1037 10647 1010 1998 1037 3259 20464 11514 1012 2065 1037 9754 2064 2022 15047 2011 1037 10647 1010 2017 2064 2022 2469 2008 1037 1006 3259 20464 11514 1007 2097 2036 11969 2009 1012 4863 2129 2017 2113 2008 6994 2052 11969 1996 9754 1012 102 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2113 1996 3259 20464 11514 2052 11969 2009 2138 1037 3259 20464 11514 2003 6211 2084 1037 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:51:47 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:51:47 - INFO - __main__ -  554 -   guid: dev-2
11/17/2020 18:51:47 - INFO - __main__ -  556 -   tokens: [CLS] you used 3 scratch tools in class to test minerals for hardness : your finger ##nail , a penny , and a paper ##cl ##ip . if a mineral can be scratched by a penny , you can be sure that a ( paper ##cl ##ip ) will also scratch it . explain how you know that tool would scratch the mineral . [SEP] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i knew that because the paper ##cl ##ip is harder than the penny . [SEP]
11/17/2020 18:51:47 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 1017 11969 5906 1999 2465 2000 3231 13246 2005 23608 1024 2115 4344 25464 1010 1037 10647 1010 1998 1037 3259 20464 11514 1012 2065 1037 9754 2064 2022 15047 2011 1037 10647 1010 2017 2064 2022 2469 2008 1037 1006 3259 20464 11514 1007 2097 2036 11969 2009 1012 4863 2129 2017 2113 2008 6994 2052 11969 1996 9754 1012 102 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2354 2008 2138 1996 3259 20464 11514 2003 6211 2084 1996 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:51:47 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:51:47 - INFO - __main__ -  554 -   guid: dev-3
11/17/2020 18:51:47 - INFO - __main__ -  556 -   tokens: [CLS] you used 3 scratch tools in class to test minerals for hardness : your finger ##nail , a penny , and a paper ##cl ##ip . if a mineral can be scratched by a penny , you can be sure that a ( paper ##cl ##ip ) will also scratch it . explain how you know that tool would scratch the mineral . [SEP] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i know that the paper ##cl ##ip would scratch the mineral because a paper ##cl ##ip is harder than a penny . [SEP]
11/17/2020 18:51:47 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 1017 11969 5906 1999 2465 2000 3231 13246 2005 23608 1024 2115 4344 25464 1010 1037 10647 1010 1998 1037 3259 20464 11514 1012 2065 1037 9754 2064 2022 15047 2011 1037 10647 1010 2017 2064 2022 2469 2008 1037 1006 3259 20464 11514 1007 2097 2036 11969 2009 1012 4863 2129 2017 2113 2008 6994 2052 11969 1996 9754 1012 102 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2113 2008 1996 3259 20464 11514 2052 11969 1996 9754 2138 1037 3259 20464 11514 2003 6211 2084 1037 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:51:47 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:51:47 - INFO - __main__ -  554 -   guid: dev-4
11/17/2020 18:51:47 - INFO - __main__ -  556 -   tokens: [CLS] you used 3 scratch tools in class to test minerals for hardness : your finger ##nail , a penny , and a paper ##cl ##ip . if a mineral can be scratched by a penny , you can be sure that a ( paper ##cl ##ip ) will also scratch it . explain how you know that tool would scratch the mineral . [SEP] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] because the paper ##cl ##ip is an easier item to scratch a rock or mineral than a penny . [SEP]
11/17/2020 18:51:47 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 1017 11969 5906 1999 2465 2000 3231 13246 2005 23608 1024 2115 4344 25464 1010 1037 10647 1010 1998 1037 3259 20464 11514 1012 2065 1037 9754 2064 2022 15047 2011 1037 10647 1010 2017 2064 2022 2469 2008 1037 1006 3259 20464 11514 1007 2097 2036 11969 2009 1012 4863 2129 2017 2113 2008 6994 2052 11969 1996 9754 1012 102 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 2138 1996 3259 20464 11514 2003 2019 6082 8875 2000 11969 1037 2600 2030 9754 2084 1037 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 18:51:47 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 18:51:47 - INFO - __main__ -  554 -   guid: dev-5
11/17/2020 18:51:47 - INFO - __main__ -  556 -   tokens: [CLS] you used 3 scratch tools in class to test minerals for hardness : your finger ##nail , a penny , and a paper ##cl ##ip . if a mineral can be scratched by a penny , you can be sure that a ( paper ##cl ##ip ) will also scratch it . explain how you know that tool would scratch the mineral . [SEP] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i know that a paper ##cl ##ip will scratch it because it is the hardest tool that we used out of a finger ##nail , penny and paper ##cl ##ip . [SEP]
11/17/2020 18:51:47 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 1017 11969 5906 1999 2465 2000 3231 13246 2005 23608 1024 2115 4344 25464 1010 1037 10647 1010 1998 1037 3259 20464 11514 1012 2065 1037 9754 2064 2022 15047 2011 1037 10647 1010 2017 2064 2022 2469 2008 1037 1006 3259 20464 11514 1007 2097 2036 11969 2009 1012 4863 2129 2017 2113 2008 6994 2052 11969 1996 9754 1012 102 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2113 2008 1037 3259 20464 11514 2097 11969 2009 2138 2009 2003 1996 18263 6994 2008 2057 2109 2041 1997 1037 4344 25464 1010 10647 1998 3259 20464 11514 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 18:51:47 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 18:51:48 - INFO - __main__ -  976 -   ***** Running evaluation *****
11/17/2020 18:51:48 - INFO - __main__ -  977 -     Num examples = 733
11/17/2020 18:51:48 - INFO - __main__ -  978 -     Batch size = 8
11/17/2020 21:56:32 - INFO - __main__ -  838 -   device: cpu n_gpu: 0, distributed training: False, 16-bits training: False
11/17/2020 21:56:35 - INFO - pytorch_pretrained_bert.tokenization -  190 -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
11/17/2020 21:56:35 - INFO - __main__ -  175 -   LOOKING AT F:\PYTHONproject\my-EAAI-25-master\traindata/sciEntsBank/A-ORIGIN\2way\train.txt
11/17/2020 21:56:35 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 21:56:35 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [By letting it sit in a dish for a day.] label: [incorrect]
11/17/2020 21:56:35 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 21:56:35 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [Let the water evaporate and the salt is left behind.] label: [correct]
11/17/2020 21:56:35 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 21:56:35 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [The water evaporated and left salt crystals.] label: [correct]
11/17/2020 21:56:35 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 21:56:35 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [I saw a pinkish grayish color that was blocking the water.] label: [incorrect]
11/17/2020 21:56:35 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 21:56:35 - INFO - __main__ -  204 -   text_a: [The water was evaporated, leaving the salt.] test_b: [You have to slowly tip the vial for only the water to go.] label: [incorrect]
11/17/2020 21:56:36 - INFO - pytorch_pretrained_bert.modeling -  583 -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
11/17/2020 21:56:36 - INFO - pytorch_pretrained_bert.modeling -  591 -   extracting archive file C:\Users\no_password\.cache\torch\pytorch_pretrained_bert\distributed_-1\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\Users\NO_PAS~1\AppData\Local\Temp\tmp2l3oarje
11/17/2020 21:56:42 - INFO - pytorch_pretrained_bert.modeling -  601 -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

11/17/2020 21:56:45 - INFO - pytorch_pretrained_bert.modeling -  651 -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
11/17/2020 21:56:45 - INFO - pytorch_pretrained_bert.modeling -  654 -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
11/17/2020 21:56:45 - INFO - __main__ -  488 -   Writing example 0 of 4969
11/17/2020 21:56:45 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 21:56:45 - INFO - __main__ -  554 -   guid: train-1
11/17/2020 21:56:45 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] by letting it sit in a dish for a day . [SEP]
11/17/2020 21:56:45 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2011 5599 2009 4133 1999 1037 9841 2005 1037 2154 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 21:56:45 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 21:56:45 - INFO - __main__ -  554 -   guid: train-2
11/17/2020 21:56:45 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] let the water eva ##por ##ate and the salt is left behind . [SEP]
11/17/2020 21:56:45 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2292 1996 2300 9345 17822 3686 1998 1996 5474 2003 2187 2369 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 21:56:45 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 21:56:45 - INFO - __main__ -  554 -   guid: train-3
11/17/2020 21:56:45 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] the water eva ##por ##ated and left salt crystals . [SEP]
11/17/2020 21:56:45 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1996 2300 9345 17822 4383 1998 2187 5474 14438 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 21:56:45 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 21:56:45 - INFO - __main__ -  554 -   guid: train-4
11/17/2020 21:56:45 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] i saw a pink ##ish gray ##ish color that was blocking the water . [SEP]
11/17/2020 21:56:45 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 1045 2387 1037 5061 4509 3897 4509 3609 2008 2001 10851 1996 2300 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 21:56:45 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 21:56:45 - INFO - __main__ -  554 -   guid: train-5
11/17/2020 21:56:45 - INFO - __main__ -  556 -   tokens: [CLS] you used several methods to separate and identify the substances in mock rocks . how did you separate the salt from the water ? [SEP] the water was eva ##por ##ated , leaving the salt . [SEP] you have to slowly tip the vial for only the water to go . [SEP]
11/17/2020 21:56:45 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 2195 4725 2000 3584 1998 6709 1996 13978 1999 12934 5749 1012 2129 2106 2017 3584 1996 5474 2013 1996 2300 1029 102 1996 2300 2001 9345 17822 4383 1010 2975 1996 5474 1012 102 2017 2031 2000 3254 5955 1996 28475 2005 2069 1996 2300 2000 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:45 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 21:56:51 - INFO - __main__ -  944 -   ***** Running training *****
11/17/2020 21:56:51 - INFO - __main__ -  945 -     Num examples = 4969
11/17/2020 21:56:51 - INFO - __main__ -  946 -     Batch size = 16
11/17/2020 21:56:51 - INFO - __main__ -  947 -     Num steps = 3100
11/17/2020 21:56:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 21:56:51 - INFO - __main__ -  204 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I know the paperclip would scratch it because a paperclip is harder than a penny.] label: [correct]
11/17/2020 21:56:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 21:56:51 - INFO - __main__ -  204 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I knew that because the paperclip is harder than the penny.] label: [correct]
11/17/2020 21:56:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 21:56:51 - INFO - __main__ -  204 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I know that the paperclip would scratch the mineral because a paperclip is harder than a penny.] label: [correct]
11/17/2020 21:56:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 21:56:51 - INFO - __main__ -  204 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [Because the paperclip is an easier item to scratch a rock or mineral than a penny.] label: [incorrect]
11/17/2020 21:56:51 - INFO - __main__ -  203 -   **** 2way samples of sciencesbank ****
11/17/2020 21:56:51 - INFO - __main__ -  204 -   text_a: [A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.] test_b: [I know that a paperclip will scratch it because it is the hardest tool that we used out of a fingernail, penny and paperclip.] label: [correct]
11/17/2020 21:56:51 - INFO - __main__ -  488 -   Writing example 0 of 733
11/17/2020 21:56:51 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 21:56:51 - INFO - __main__ -  554 -   guid: dev-1
11/17/2020 21:56:51 - INFO - __main__ -  556 -   tokens: [CLS] you used 3 scratch tools in class to test minerals for hardness : your finger ##nail , a penny , and a paper ##cl ##ip . if a mineral can be scratched by a penny , you can be sure that a ( paper ##cl ##ip ) will also scratch it . explain how you know that tool would scratch the mineral . [SEP] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i know the paper ##cl ##ip would scratch it because a paper ##cl ##ip is harder than a penny . [SEP]
11/17/2020 21:56:51 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 1017 11969 5906 1999 2465 2000 3231 13246 2005 23608 1024 2115 4344 25464 1010 1037 10647 1010 1998 1037 3259 20464 11514 1012 2065 1037 9754 2064 2022 15047 2011 1037 10647 1010 2017 2064 2022 2469 2008 1037 1006 3259 20464 11514 1007 2097 2036 11969 2009 1012 4863 2129 2017 2113 2008 6994 2052 11969 1996 9754 1012 102 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2113 1996 3259 20464 11514 2052 11969 2009 2138 1037 3259 20464 11514 2003 6211 2084 1037 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 21:56:51 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 21:56:51 - INFO - __main__ -  554 -   guid: dev-2
11/17/2020 21:56:51 - INFO - __main__ -  556 -   tokens: [CLS] you used 3 scratch tools in class to test minerals for hardness : your finger ##nail , a penny , and a paper ##cl ##ip . if a mineral can be scratched by a penny , you can be sure that a ( paper ##cl ##ip ) will also scratch it . explain how you know that tool would scratch the mineral . [SEP] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i knew that because the paper ##cl ##ip is harder than the penny . [SEP]
11/17/2020 21:56:51 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 1017 11969 5906 1999 2465 2000 3231 13246 2005 23608 1024 2115 4344 25464 1010 1037 10647 1010 1998 1037 3259 20464 11514 1012 2065 1037 9754 2064 2022 15047 2011 1037 10647 1010 2017 2064 2022 2469 2008 1037 1006 3259 20464 11514 1007 2097 2036 11969 2009 1012 4863 2129 2017 2113 2008 6994 2052 11969 1996 9754 1012 102 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2354 2008 2138 1996 3259 20464 11514 2003 6211 2084 1996 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 21:56:51 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 21:56:51 - INFO - __main__ -  554 -   guid: dev-3
11/17/2020 21:56:51 - INFO - __main__ -  556 -   tokens: [CLS] you used 3 scratch tools in class to test minerals for hardness : your finger ##nail , a penny , and a paper ##cl ##ip . if a mineral can be scratched by a penny , you can be sure that a ( paper ##cl ##ip ) will also scratch it . explain how you know that tool would scratch the mineral . [SEP] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i know that the paper ##cl ##ip would scratch the mineral because a paper ##cl ##ip is harder than a penny . [SEP]
11/17/2020 21:56:51 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 1017 11969 5906 1999 2465 2000 3231 13246 2005 23608 1024 2115 4344 25464 1010 1037 10647 1010 1998 1037 3259 20464 11514 1012 2065 1037 9754 2064 2022 15047 2011 1037 10647 1010 2017 2064 2022 2469 2008 1037 1006 3259 20464 11514 1007 2097 2036 11969 2009 1012 4863 2129 2017 2113 2008 6994 2052 11969 1996 9754 1012 102 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2113 2008 1996 3259 20464 11514 2052 11969 1996 9754 2138 1037 3259 20464 11514 2003 6211 2084 1037 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 21:56:51 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 21:56:51 - INFO - __main__ -  554 -   guid: dev-4
11/17/2020 21:56:51 - INFO - __main__ -  556 -   tokens: [CLS] you used 3 scratch tools in class to test minerals for hardness : your finger ##nail , a penny , and a paper ##cl ##ip . if a mineral can be scratched by a penny , you can be sure that a ( paper ##cl ##ip ) will also scratch it . explain how you know that tool would scratch the mineral . [SEP] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] because the paper ##cl ##ip is an easier item to scratch a rock or mineral than a penny . [SEP]
11/17/2020 21:56:51 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 1017 11969 5906 1999 2465 2000 3231 13246 2005 23608 1024 2115 4344 25464 1010 1037 10647 1010 1998 1037 3259 20464 11514 1012 2065 1037 9754 2064 2022 15047 2011 1037 10647 1010 2017 2064 2022 2469 2008 1037 1006 3259 20464 11514 1007 2097 2036 11969 2009 1012 4863 2129 2017 2113 2008 6994 2052 11969 1996 9754 1012 102 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 2138 1996 3259 20464 11514 2003 2019 6082 8875 2000 11969 1037 2600 2030 9754 2084 1037 10647 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  561 -   label: incorrect (id = 1)
11/17/2020 21:56:51 - INFO - __main__ -  553 -   *** Example ***
11/17/2020 21:56:51 - INFO - __main__ -  554 -   guid: dev-5
11/17/2020 21:56:51 - INFO - __main__ -  556 -   tokens: [CLS] you used 3 scratch tools in class to test minerals for hardness : your finger ##nail , a penny , and a paper ##cl ##ip . if a mineral can be scratched by a penny , you can be sure that a ( paper ##cl ##ip ) will also scratch it . explain how you know that tool would scratch the mineral . [SEP] a paper ##cl ##ip is harder than a penny , so if a penny can scratch a mineral , a paper ##cl ##ip can also scratch the mineral . [SEP] i know that a paper ##cl ##ip will scratch it because it is the hardest tool that we used out of a finger ##nail , penny and paper ##cl ##ip . [SEP]
11/17/2020 21:56:51 - INFO - __main__ -  557 -   input_ids: 101 2017 2109 1017 11969 5906 1999 2465 2000 3231 13246 2005 23608 1024 2115 4344 25464 1010 1037 10647 1010 1998 1037 3259 20464 11514 1012 2065 1037 9754 2064 2022 15047 2011 1037 10647 1010 2017 2064 2022 2469 2008 1037 1006 3259 20464 11514 1007 2097 2036 11969 2009 1012 4863 2129 2017 2113 2008 6994 2052 11969 1996 9754 1012 102 1037 3259 20464 11514 2003 6211 2084 1037 10647 1010 2061 2065 1037 10647 2064 11969 1037 9754 1010 1037 3259 20464 11514 2064 2036 11969 1996 9754 1012 102 1045 2113 2008 1037 3259 20464 11514 2097 11969 2009 2138 2009 2003 1996 18263 6994 2008 2057 2109 2041 1997 1037 4344 25464 1010 10647 1998 3259 20464 11514 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  558 -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  560 -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
11/17/2020 21:56:51 - INFO - __main__ -  561 -   label: correct (id = 0)
11/17/2020 21:56:51 - INFO - __main__ -  976 -   ***** Running evaluation *****
11/17/2020 21:56:51 - INFO - __main__ -  977 -     Num examples = 733
11/17/2020 21:56:51 - INFO - __main__ -  978 -     Batch size = 8
